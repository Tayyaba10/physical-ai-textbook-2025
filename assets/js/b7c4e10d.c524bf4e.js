"use strict";(globalThis.webpackChunkai_native_robotics_textbook=globalThis.webpackChunkai_native_robotics_textbook||[]).push([[73],{985:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>p,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-4-vision-language-action/ch19-cognitive-task-planning-gpt4o","title":"ch19-cognitive-task-planning-gpt4o","description":"-----","source":"@site/docs/module-4-vision-language-action/ch19-cognitive-task-planning-gpt4o.md","sourceDirName":"module-4-vision-language-action","slug":"/module-4-vision-language-action/ch19-cognitive-task-planning-gpt4o","permalink":"/physical-ai-textbook-2025/docs/module-4-vision-language-action/ch19-cognitive-task-planning-gpt4o","draft":false,"unlisted":false,"editUrl":"https://github.com/Tayyaba10/physical-ai-textbook-2025/edit/main/docs/module-4-vision-language-action/ch19-cognitive-task-planning-gpt4o.md","tags":[],"version":"current","frontMatter":{}}');var a=r(4848),i=r(8453),s=r(7242);const o={},l=void 0,p={},c=[{value:"title: Ch19  Cognitive Task Planning with GPT4o\r\nmodule: 4\r\nchapter: 19\r\nsidebar_label: Ch19: Cognitive Task Planning with GPT4o\r\ndescription: Implementing highlevel cognitive task planning using OpenAI GPT models for robotics\r\ntags: [gpt4o, cognitiveplanning, taskplanning, robotics, aiplanning, hierarchicaltasknetwork, ros2]\r\ndifficulty: advanced\r\nestimated_duration: 120",id:"title-ch19--cognitive-task-planning-with-gpt4omodule-4chapter-19sidebar_label-ch19-cognitive-task-planning-with-gpt4odescription-implementing-highlevel-cognitive-task-planning-using-openai-gpt-models-for-roboticstags-gpt4o-cognitiveplanning-taskplanning-robotics-aiplanning-hierarchicaltasknetwork-ros2difficulty-advancedestimated_duration-120",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Theory",id:"theory",level:2},{value:"Cognitive Task Planning Fundamentals",id:"cognitive-task-planning-fundamentals",level:3},{value:"GPT4o for Task Planning",id:"gpt4o-for-task-planning",level:3},{value:"Hierarchical Task Networks (HTNs)",id:"hierarchical-task-networks-htns",level:3},{value:"Integration with Traditional Planning",id:"integration-with-traditional-planning",level:3},{value:"Context Integration",id:"context-integration",level:3},{value:"StepbyStep Labs",id:"stepbystep-labs",level:2},{value:"Lab 1: Setting up GPT4o Integration for Planning",id:"lab-1-setting-up-gpt4o-integration-for-planning",level:3},{value:"Lab 2: Creating Hierarchical Task Networks with GPT4o",id:"lab-2-creating-hierarchical-task-networks-with-gpt4o",level:3},{value:"Lab 3: Integrating with ROS Navigation Stack",id:"lab-3-integrating-with-ros-navigation-stack",level:3},{value:"Runnable Code Example",id:"runnable-code-example",level:2},{value:"Launch file for the system:",id:"launch-file-for-the-system",level:3},{value:"Miniproject",id:"miniproject",level:2},{value:"Summary",id:"summary",level:2}];function _(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"title-ch19--cognitive-task-planning-with-gpt4omodule-4chapter-19sidebar_label-ch19-cognitive-task-planning-with-gpt4odescription-implementing-highlevel-cognitive-task-planning-using-openai-gpt-models-for-roboticstags-gpt4o-cognitiveplanning-taskplanning-robotics-aiplanning-hierarchicaltasknetwork-ros2difficulty-advancedestimated_duration-120",children:"title: Ch19  Cognitive Task Planning with GPT4o\r\nmodule: 4\r\nchapter: 19\r\nsidebar_label: Ch19: Cognitive Task Planning with GPT4o\r\ndescription: Implementing highlevel cognitive task planning using OpenAI GPT models for robotics\r\ntags: [gpt4o, cognitiveplanning, taskplanning, robotics, aiplanning, hierarchicaltasknetwork, ros2]\r\ndifficulty: advanced\r\nestimated_duration: 120"}),"\n","\n",(0,a.jsx)(e.h1,{id:"cognitive-task-planning-with-gpt4o",children:"Cognitive Task Planning with GPT4o"}),"\n",(0,a.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,a.jsx)(e.p,{children:"Understand cognitive task planning in robotics using LLMs\r\nImplement GPT4o integration for highlevel task decomposition\r\nCreate hierarchical task networks with LLM guidance\r\nDevelop contextaware planning systems\r\nIntegrate LLMbased planning with traditional ROS 2 planning systems\r\nImplement plan validation and safety checks\r\nHandle multistep task execution and monitoring\r\nCreate fallback and recovery mechanisms for plan failures\r\nEvaluate planning performance and success rates"}),"\n",(0,a.jsx)(e.h2,{id:"theory",children:"Theory"}),"\n",(0,a.jsx)(e.h3,{id:"cognitive-task-planning-fundamentals",children:"Cognitive Task Planning Fundamentals"}),"\n",(0,a.jsx)(e.p,{children:'Cognitive task planning involves highlevel reasoning about complex tasks that require understanding of the environment, objects, and their relationships. Traditional robotics planning focuses on lowlevel motion planning, while cognitive planning addresses the "what" and "why" of robot actions.'}),"\n",(0,a.jsx)(s.A,{chart:"\ngraph TD;\n  A[Cognitive Task Planning] > B[Task Decomposition];\n  A > C[Context Understanding];\n  A > D[Knowledge Integration];\n  A > E[Reasoning & Inference];\n  \n  B > F[HighLevel Goals];\n  B > G[Intermediate Steps];\n  B > H[Primitive Actions];\n  \n  C > I[Environmental State];\n  C > J[Object Affordances];\n  C > K[Robot Capabilities];\n  \n  D > L[Common Sense];\n  D > M[World Knowledge];\n  D > N[Physical Laws];\n  \n  E > O[Logical Reasoning];\n  E > P[Causal Inference];\n  E > Q[Plan Validation];\n  \n  R[Robot] > S[Traditional Planner];\n  T[GPT4o] > U[Cognitive Planner];\n  \n  S > V[LowLevel Motion];\n  U > W[HighLevel Reasoning];\n  U > X[Context Integration];\n  \n  V > Y[Path Planning];\n  W > Z[Task Sequencing];\n  X > AA[Constraint Checking];\n  \n  BB[Human] > CC[Natural Language Task];\n  CC > U;\n  W > DD[Robot Action Sequence];\n  DD > R;\n  \n  style A fill:#4CAF50,stroke:#388E3C,color:#fff;\n  style T fill:#2196F3,stroke:#0D47A1,color:#fff;\n  style CC fill:#FF9800,stroke:#E65100,color:#fff;\n  style DD fill:#E91E63,stroke:#AD1457,color:#fff;\n"}),"\n",(0,a.jsx)(e.h3,{id:"gpt4o-for-task-planning",children:"GPT4o for Task Planning"}),"\n",(0,a.jsx)(e.p,{children:"GPT4o provides several advantages for cognitive task planning:"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"World Knowledge"}),": Comprehensive understanding of physical objects, their properties, and relationships\r\n",(0,a.jsx)(e.strong,{children:"Logical Reasoning"}),": Ability to reason about cause and effect, preconditions, and effects\r\n",(0,a.jsx)(e.strong,{children:"Contextual Understanding"}),": Incorporation of environmental context into planning\r\n",(0,a.jsx)(e.strong,{children:"Natural Language Interface"}),": Direct translation of human instructions to robot actions\r\n",(0,a.jsx)(e.strong,{children:"Flexibility"}),": Ability to handle novel situations and adapt plans"]}),"\n",(0,a.jsx)(e.h3,{id:"hierarchical-task-networks-htns",children:"Hierarchical Task Networks (HTNs)"}),"\n",(0,a.jsx)(e.p,{children:"HTNs decompose complex tasks into hierarchically organized subtasks. The planning process involves:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Task Decomposition"}),": Breaking highlevel goals into subtasks"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Constraint Propagation"}),": Maintaining consistency across subtask relationships"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Resource Allocation"}),": Ensuring resource requirements are met"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Temporal Scheduling"}),": Ordering subtasks according to dependencies"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"integration-with-traditional-planning",children:"Integration with Traditional Planning"}),"\n",(0,a.jsx)(e.p,{children:"Cognitive planning should integrate with traditional robotic planning systems:"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"HighLevel"}),": LLM handles task decomposition and contextual reasoning\r\n",(0,a.jsx)(e.strong,{children:"MidLevel"}),": ROS navigation stack handles path planning and execution\r\n",(0,a.jsx)(e.strong,{children:"LowLevel"}),": Motion controllers handle trajectory execution and feedback"]}),"\n",(0,a.jsx)(e.h3,{id:"context-integration",children:"Context Integration"}),"\n",(0,a.jsx)(e.p,{children:"For effective task planning, GPT4o must incorporate context from:"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Current State"}),": Robot pose, battery level, internal state\r\n",(0,a.jsx)(e.strong,{children:"Environmental State"}),": Sensor data from cameras, LiDAR, etc.\r\n",(0,a.jsx)(e.strong,{children:"Historical Context"}),": Previous tasks, learned preferences\r\n",(0,a.jsx)(e.strong,{children:"Constraint Information"}),": Safety requirements, operational constraints"]}),"\n",(0,a.jsx)(e.h2,{id:"stepbystep-labs",children:"StepbyStep Labs"}),"\n",(0,a.jsx)(e.h3,{id:"lab-1-setting-up-gpt4o-integration-for-planning",children:"Lab 1: Setting up GPT4o Integration for Planning"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Install required dependencies"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"pip install openai==1.3.5\r\npip install langchain langchainopenai\r\npip install pythondotenv\r\npip install ros2 rospy std_msgs geometry_msgs actionlib_msgs\r\npip install py_trees  # For behavior trees integration\n"})}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Create a GPT4o planning interface"})," (",(0,a.jsx)(e.code,{children:"gpt_planning_interface.py"}),"):"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n\r\nimport openai\r\nimport rospy\r\nimport json\r\nimport time\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import PoseStamped\r\nfrom sensor_msgs.msg import LaserScan\r\nfrom actionlib_msgs.msg import GoalStatusArray\r\nfrom typing import Dict, List, Optional\r\nimport threading\r\nimport queue\r\n\r\nclass GPTPlanningInterface:\r\n    def __init__(self, api_key: str):\r\n        # Initialize OpenAI client\r\n        self.client = openai.OpenAI(api_key=api_key)\r\n        self.model_name = "gpt4o"\r\n        \r\n        # Initialize ROS\r\n        rospy.init_node(\'gpt_planning_interface\', anonymous=True)\r\n        \r\n        # Publishers and Subscribers\r\n        self.plan_pub = rospy.Publisher(\'/gpt_generated_plan\', String, queue_size=10)\r\n        self.status_pub = rospy.Publisher(\'/gpt_planner_status\', String, queue_size=10)\r\n        self.feedback_pub = rospy.Publisher(\'/gpt_planning_feedback\', String, queue_size=10)\r\n        \r\n        rospy.Subscriber(\'/task_request\', String, self.task_request_callback)\r\n        rospy.Subscriber(\'/robot_state\', String, self.robot_state_callback)\r\n        rospy.Subscriber(\'/environment_state\', String, self.environment_state_callback)\r\n        rospy.Subscriber(\'/execution_feedback\', String, self.execution_feedback_callback)\r\n        \r\n        # Internal state\r\n        self.robot_state = {}\r\n        self.environment_state = {}\r\n        self.current_task = None\r\n        self.current_plan = None\r\n        self.plan_queue = queue.Queue()\r\n        \r\n        # Planning parameters\r\n        self.max_retries = 3\r\n        self.planning_timeout = 30.0\r\n        \r\n        rospy.loginfo("GPT Planning Interface initialized")\r\n    \r\n    def task_request_callback(self, msg: String):\r\n        """Handle new task requests"""\r\n        task_data = json.loads(msg.data) if msg.data.startswith(\'{\') else {"task": msg.data}\r\n        task_description = task_data.get("task", "")\r\n        priority = task_data.get("priority", "normal")\r\n        \r\n        rospy.loginfo(f"Received task request: {task_description} (Priority: {priority})")\r\n        \r\n        # Add to planning queue\r\n        self.plan_queue.put({\r\n            "task": task_description,\r\n            "priority": priority,\r\n            "timestamp": rospy.Time.now().to_sec(),\r\n            "task_id": time.time_ns()  # Unique identifier\r\n        })\r\n    \r\n    def robot_state_callback(self, msg: String):\r\n        """Update robot state"""\r\n        try:\r\n            self.robot_state = json.loads(msg.data)\r\n            rospy.logdebug(f"Updated robot state: {self.robot_state.keys()}")\r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Failed to decode robot state")\r\n    \r\n    def environment_state_callback(self, msg: String):\r\n        """Update environment state"""\r\n        try:\r\n            self.environment_state = json.loads(msg.data)\r\n            rospy.logdebug(f"Updated environment state: {self.environment_state.keys()}")\r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Failed to decode environment state")\r\n    \r\n    def execution_feedback_callback(self, msg: String):\r\n        """Handle execution feedback for plan monitoring"""\r\n        try:\r\n            feedback = json.loads(msg.data)\r\n            task_id = feedback.get("task_id")\r\n            status = feedback.get("status")  # "success", "failure", "in_progress"\r\n            step_completed = feedback.get("step_completed", 1)\r\n            \r\n            if status == "failure" and self.current_plan and self.current_plan.get("task_id") == task_id:\r\n                rospy.logwarn(f"Current plan failed at step {step_completed}")\r\n                self.handle_plan_failure(task_id, step_completed, feedback.get("error", ""))\r\n            \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Failed to decode execution feedback")\r\n    \r\n    def handle_plan_failure(self, task_id: str, step_num: int, error: str):\r\n        """Handle plan execution failure"""\r\n        rospy.loginfo(f"Handling plan failure for task {task_id}, step {step_num}")\r\n        \r\n        # Generate recovery plan\r\n        recovery_plan = self.generate_recovery_plan(task_id, step_num, error)\r\n        \r\n        if recovery_plan:\r\n            rospy.loginfo("Recovery plan generated successfully")\r\n            self.publish_plan(recovery_plan)\r\n            self.publish_feedback({\r\n                "message": f"Recovery plan generated for failed step {step_num}",\r\n                "type": "recovery",\r\n                "task_id": task_id\r\n            })\r\n        else:\r\n            rospy.logerr("Failed to generate recovery plan")\r\n            self.publish_feedback({\r\n                "message": f"Could not generate recovery plan for failure at step {step_num}",\r\n                "type": "error",\r\n                "task_id": task_id\r\n            })\r\n    \r\n    def generate_recovery_plan(self, task_id: str, failed_step: int, error: str) > Optional[Dict]:\r\n        """Generate recovery plan when original plan fails"""\r\n        # Get context at time of failure\r\n        context = {\r\n            "robot_state": self.robot_state,\r\n            "environment_state": self.environment_state,\r\n            "original_task": self.current_task,\r\n            "failed_step": failed_step,\r\n            "error": error\r\n        }\r\n        \r\n        prompt = f"""\r\n        Original Task: {self.current_task}\r\n        \r\n        Plan Failed at Step: {failed_step}\r\n        Error Encountered: {error}\r\n        \r\n        Current Robot State: {json.dumps(self.robot_state, indent=2)}\r\n        Current Environment State: {json.dumps(self.environment_state, indent=2)}\r\n        \r\n        Available Robot Capabilities:\r\n         Navigation: move_to_location, navigate_to_object\r\n         Manipulation: grasp_object, place_object, open_container, close_container\r\n         Perception: detect_object, inspect_area\r\n         Communication: speak_text, play_sound\r\n        \r\n        Generate a recovery plan that:\r\n        1. Addresses the specific failure that occurred\r\n        2. Attempts to resume the original task if possible\r\n        3. Includes alternative strategies if the original approach failed\r\n        4. Considers the current robot state and environment\r\n        5. Is executable by the robot\r\n        \r\n        Return the plan as JSON with the structure:\r\n        {{\r\n          "task_id": "original_task_id",\r\n          "task": "original task with recovery context",\r\n          "plan_type": "recovery",\r\n          "recovery_strategy": "strategy_used",\r\n          "steps": [\r\n            {{\r\n              "id": 1,\r\n              "action": "action_type",\r\n              "parameters": {{"param1": "value1"}},\r\n              "description": "what this step does",\r\n              "preconditions": ["condition1", "condition2"],\r\n              "expected_effects": ["effect1", "effect2"],\r\n              "estimated_duration": 10.0\r\n            }}\r\n          ],\r\n          "estimated_completion_time": 120.0,\r\n          "confidence": 0.8,\r\n          "fallback_options": ["option1", "option2"]\r\n        }}\r\n        \r\n        Only return the JSON plan, no other text.\r\n        """\r\n        \r\n        try:\r\n            response = self.client.chat.completions.create(\r\n                model=self.model_name,\r\n                messages=[\r\n                    {\r\n                        "role": "system",\r\n                        "content": "You are a robot task recovery planner. Generate recovery plans that address specific failures and attempt to continue task completion. Only return valid JSON."\r\n                    },\r\n                    {\r\n                        "role": "user",\r\n                        "content": prompt\r\n                    }\r\n                ],\r\n                temperature=0.1,\r\n                max_tokens=1500\r\n            )\r\n            \r\n            response_text = response.choices[0].message.content.strip()\r\n            \r\n            # Extract JSON if wrapped in code block\r\n            if response_text.startswith(\'```\'):\r\n                start_idx = response_text.find(\'{\')\r\n                end_idx = response_text.rfind(\'}\') + 1\r\n                if start_idx != 1 and end_idx != 1:\r\n                    response_text = response_text[start_idx:end_idx]\r\n            \r\n            recovery_plan = json.loads(response_text)\r\n            recovery_plan["timestamp"] = rospy.Time.now().to_sec()\r\n            \r\n            return recovery_plan\r\n            \r\n        except Exception as e:\r\n            rospy.logerr(f"Error generating recovery plan: {e}")\r\n            return None\r\n    \r\n    def run_planning_loop(self):\r\n        """Main planning loop to process tasks asynchronously"""\r\n        rate = rospy.Rate(1)  # 1 Hz polling of task queue\r\n        \r\n        while not rospy.is_shutdown():\r\n            try:\r\n                # Get next task from queue\r\n                task_request = self.plan_queue.get(timeout=1.0)\r\n                \r\n                # Generate plan for task\r\n                plan = self.generate_plan(task_request)\r\n                \r\n                if plan:\r\n                    self.current_plan = plan\r\n                    self.current_task = task_request["task"]\r\n                    self.publish_plan(plan)\r\n                    self.publish_status(f"Plan generated for task ID: {task_request[\'task_id\']}")\r\n                else:\r\n                    self.publish_status(f"Failed to generate plan for task ID: {task_request[\'task_id\']}")\r\n                    self.publish_feedback({\r\n                        "message": "Plan generation failed",\r\n                        "type": "error",\r\n                        "task_id": task_request[\'task_id\']\r\n                    })\r\n                \r\n                self.plan_queue.task_done()\r\n                \r\n            except queue.Empty:\r\n                continue\r\n            except Exception as e:\r\n                rospy.logerr(f"Error in planning loop: {e}")\r\n                continue\r\n            \r\n            rate.sleep()\r\n    \r\n    def generate_plan(self, task_request: Dict) > Optional[Dict]:\r\n        """Generate a plan using GPT4o"""\r\n        task_description = task_request["task"]\r\n        \r\n        # Construct planning context\r\n        context = {\r\n            "robot_capabilities": self.robot_state.get("capabilities", []),\r\n            "current_robot_state": self.robot_state,\r\n            "environment_objects": self.environment_state.get("objects", []),\r\n            "known_locations": self.environment_state.get("locations", []),\r\n            "previous_experiences": self.environment_state.get("historical_tasks", []),\r\n            "safety_constraints": ["avoid_obstacles", "maintain_battery_above_20_percent"],\r\n            "time_constraints": task_request.get("deadline", "none")\r\n        }\r\n        \r\n        # Create detailed planning prompt\r\n        prompt = f"""\r\n        Task to Plan: {task_description}\r\n        \r\n        Context Information:\r\n        Robot Capabilities: {json.dumps(context[\'robot_capabilities\'])}\r\n        Current Robot State: {json.dumps(context[\'current_robot_state\'])}\r\n        Environmental Objects: {json.dumps(context[\'environment_objects\'])}\r\n        Known Locations: {json.dumps(context[\'known_locations\'])}\r\n        Safety Constraints: {json.dumps(context[\'safety_constraints\'])}\r\n        Time Constraints: {context[\'time_constraints\']}\r\n        \r\n        Available HighLevel Actions:\r\n         navigate: Move robot to a location or object\r\n          Parameters: target_location, speed, safety_margin\r\n         manipulate: Manipulate objects\r\n          Parameters: action (grasp/place/open/close), object_name, grasp_pose\r\n         perceive: Use sensors to gather information\r\n          Parameters: type (detect/inspect/recognize), target_object\r\n         communicate: Interact with humans or systems\r\n          Parameters: message_type, content, target_recipient\r\n         wait: Pause execution\r\n          Parameters: duration, condition_to_monitor\r\n        \r\n        Generate a detailed plan that:\r\n        1. Breaks the highlevel task into a sequence of specific actions\r\n        2. Considers the robot\'s capabilities and current state\r\n        3. Takes environmental context into account\r\n        4. Respects safety and temporal constraints\r\n        5. Handles potential failure modes\r\n        6. Includes success criteria for each step\r\n        \r\n        The plan should be in JSON format:\r\n        {{\r\n          "task_id": "{task_request[\'task_id\']}",\r\n          "task": "{task_description}",\r\n          "plan_type": "high_level",\r\n          "steps": [\r\n            {{\r\n              "id": 1,\r\n              "action": "action_type",\r\n              "parameters": {{"param1": "value1", "param2": "value2"}},\r\n              "description": "Detailed description of what this step accomplishes",\r\n              "preconditions": [\r\n                "conditions that must be true before step execution"\r\n              ],\r\n              "expected_effects": [\r\n                "expected outcomes of the step execution"\r\n              ],\r\n              "execution_constraints": [\r\n                "time limits, safety requirements, etc."\r\n              ],\r\n              "failure_recovery": [\r\n                "actions to take if this step fails"\r\n              ],\r\n              "success_criteria": [\r\n                "how to verify step completion"\r\n              ],\r\n              "estimated_duration": 15.0,\r\n              "confidence": 0.8\r\n            }}\r\n          ],\r\n          "total_estimated_duration": 120.0,\r\n          "overall_confidence": 0.75,\r\n          "risk_factors": ["factor1", "factor2"],\r\n          "validation_steps": [\r\n            "steps to verify plan feasibility before execution"\r\n          ]\r\n        }}\r\n        \r\n        Only return the JSON plan with no other text.\r\n        """\r\n        \r\n        try:\r\n            response = self.client.chat.completions.create(\r\n                model=self.model_name,\r\n                messages=[\r\n                    {\r\n                        "role": "system", \r\n                        "content": "You are an advanced robotic task planner. Generate detailed, executable plans that consider robot capabilities, environmental context, and safety constraints. Respond only with valid JSON."\r\n                    },\r\n                    {\r\n                        "role": "user",\r\n                        "content": prompt\r\n                    }\r\n                ],\r\n                temperature=0.1,  # Low temperature for consistency\r\n                max_tokens=2500\r\n            )\r\n            \r\n            response_text = response.choices[0].message.content.strip()\r\n            \r\n            # Extract JSON from response\r\n            if response_text.startswith(\'```\'):\r\n                start_idx = response_text.find(\'{\')\r\n                end_idx = response_text.rfind(\'}\') + 1\r\n                if start_idx != 1 and end_idx != 1:\r\n                    response_text = response_text[start_idx:end_idx]\r\n            \r\n            plan_data = json.loads(response_text)\r\n            plan_data["timestamp"] = rospy.Time.now().to_sec()\r\n            \r\n            # Validate plan structure\r\n            if self.validate_plan_structure(plan_data):\r\n                rospy.loginfo(f"Generated valid plan with {len(plan_data[\'steps\'])} steps")\r\n                return plan_data\r\n            else:\r\n                rospy.logerr("Generated plan failed validation")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            rospy.logerr(f"Error generating plan: {e}")\r\n            return None\r\n    \r\n    def validate_plan_structure(self, plan: Dict) > bool:\r\n        """Validate the structure of a generated plan"""\r\n        required_fields = ["task_id", "task", "steps", "overall_confidence"]\r\n        step_required_fields = ["id", "action", "parameters", "description", "success_criteria"]\r\n        \r\n        # Check toplevel fields\r\n        if not all(field in plan for field in required_fields):\r\n            rospy.logerr("Plan missing required toplevel fields")\r\n            return False\r\n        \r\n        # Check plan steps\r\n        if not isinstance(plan["steps"], list) or len(plan["steps"]) == 0:\r\n            rospy.logerr("Plan has no steps or steps not in list format")\r\n            return False\r\n        \r\n        # Validate each step\r\n        for step in plan["steps"]:\r\n            if not all(field in step for field in step_required_fields):\r\n                rospy.logerr(f"Step {step.get(\'id\', \'unknown\')} missing required fields")\r\n                return False\r\n            \r\n            # Validate action type (should be in known action types)\r\n            valid_actions = ["navigate", "manipulate", "perceive", "communicate", "wait"]\r\n            if step["action"] not in valid_actions:\r\n                rospy.logwarn(f"Unknown action type in step {step[\'id\']}: {step[\'action\']}")\r\n        \r\n        return True\r\n    \r\n    def publish_plan(self, plan: Dict):\r\n        """Publish generated plan"""\r\n        plan_msg = String()\r\n        plan_msg.data = json.dumps(plan, indent=2)\r\n        self.plan_pub.publish(plan_msg)\r\n    \r\n    def publish_status(self, status: str):\r\n        """Publish planner status"""\r\n        status_msg = String()\r\n        status_msg.data = json.dumps({\r\n            "status": status,\r\n            "timestamp": rospy.Time.now().to_sec()\r\n        })\r\n        self.status_pub.publish(status_msg)\r\n    \r\n    def publish_feedback(self, feedback: Dict):\r\n        """Publish planning feedback"""\r\n        feedback_msg = String()\r\n        feedback_msg.data = json.dumps(feedback, indent=2)\r\n        self.feedback_pub.publish(feedback_msg)\r\n\r\nclass GPTPlanningNode:\r\n    def __init__(self):\r\n        self.planner_interface = None\r\n    \r\n    def run(self):\r\n        # Get API key from parameter\r\n        api_key = rospy.get_param(\'~openai_api_key\', \'\')\r\n        if not api_key:\r\n            api_key = input("Enter OpenAI API key: ").strip()\r\n        \r\n        if not api_key:\r\n            rospy.logerr("No OpenAI API key provided!")\r\n            return\r\n        \r\n        self.planner_interface = GPTPlanningInterface(api_key)\r\n        \r\n        # Start planning loop in separate thread\r\n        planning_thread = threading.Thread(target=self.planner_interface.run_planning_loop)\r\n        planning_thread.daemon = True\r\n        planning_thread.start()\r\n        \r\n        rospy.loginfo("GPT Planning Node running...")\r\n        rospy.spin()\r\n\r\ndef main():\r\n    rospy.init_node(\'gpt_planning_node\', anonymous=True)\r\n    node = GPTPlanningNode()\r\n    node.run()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"lab-2-creating-hierarchical-task-networks-with-gpt4o",children:"Lab 2: Creating Hierarchical Task Networks with GPT4o"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Create an HTN planner with GPT4o guidance"})," (",(0,a.jsx)(e.code,{children:"htn_gpt_planner.py"}),"):","\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n\r\nimport openai\r\nimport rospy\r\nimport json\r\nimport time\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import PoseStamped\r\nfrom actionlib_msgs.msg import GoalID\r\nfrom typing import Dict, List, Optional, Tuple\r\nimport threading\r\nimport queue\r\nimport re\r\n\r\nclass GPTHierarchicalPlanner:\r\n    def __init__(self, api_key: str):\r\n        # Initialize OpenAI client\r\n        self.client = openai.OpenAI(api_key=api_key)\r\n        self.model_name = "gpt4o"\r\n        \r\n        # Initialize ROS\r\n        rospy.init_node(\'gpt_hierarchical_planner\', anonymous=True)\r\n        \r\n        # Publishers and Subscribers\r\n        self.high_level_plan_pub = rospy.Publisher(\'/hl_plan\', String, queue_size=10)\r\n        self.low_level_plan_pub = rospy.Publisher(\'/ll_plan\', String, queue_size=10)\r\n        self.plan_status_pub = rospy.Publisher(\'/plan_status\', String, queue_size=10)\r\n        \r\n        rospy.Subscriber(\'/high_level_task\', String, self.hl_task_callback)\r\n        rospy.Subscriber(\'/task_decomposition_request\', String, self.decomposition_request_callback)\r\n        rospy.Subscriber(\'/plan_execution_feedback\', String, self.execution_feedback_callback)\r\n        \r\n        # Internal state\r\n        self.current_plan = None\r\n        self.plan_history = []\r\n        self.max_history_size = 100\r\n        \r\n        # Knowledge base for planning\r\n        self.knowledge_base = {\r\n            "object_affordances": {\r\n                "cup": ["grasp", "move", "fill", "contain"],\r\n                "table": ["support", "place_on", "surface_for"],\r\n                "drawer": ["open", "close", "contain", "access"],\r\n                "door": ["open", "close", "pass_through", "barrier"],\r\n                "bottle": ["grasp", "pour", "contain", "manipulate"],\r\n                "book": ["grasp", "read", "organize", "locate"],\r\n                "chair": ["occupy", "move", "support", "sit_on"]\r\n            },\r\n            "spatial_relations": [\r\n                "left_of", "right_of", "in_front_of", "behind", \r\n                "next_to", "on_top_of", "under", "inside",\r\n                "near", "far", "between", "above", "below"\r\n            ],\r\n            "robot_capabilities": {\r\n                "navigation": {\r\n                    "actions": ["navigate_to", "go_to", "move_to", "reach"],\r\n                    "constraints": ["no_collision", "reachable", "known_map"]\r\n                },\r\n                "manipulation": {\r\n                    "actions": ["grasp", "place", "pick", "put_down", "open", "close"],\r\n                    "constraints": ["reachable", "graspable", "manipulable"]\r\n                },\r\n                "perception": {\r\n                    "actions": ["detect", "recognize", "inspect", "localize"],\r\n                    "constraints": ["visible", "sensor_range"]\r\n                }\r\n            }\r\n        }\r\n        \r\n        rospy.loginfo("GPT Hierarchical Planner initialized")\r\n    \r\n    def hl_task_callback(self, msg: String):\r\n        """Handle highlevel task requests"""\r\n        try:\r\n            task_data = json.loads(msg.data)\r\n            task_description = task_data["task"]\r\n            priority = task_data.get("priority", "normal")\r\n            deadline = task_data.get("deadline", None)\r\n            \r\n            rospy.loginfo(f"Highlevel task received: {task_description}")\r\n            \r\n            # Generate hierarchical plan\r\n            plan = self.generate_hierarchical_plan(task_description, priority, deadline)\r\n            \r\n            if plan:\r\n                self.current_plan = plan\r\n                self.add_to_plan_history(plan)\r\n                self.publish_hierarchical_plan(plan)\r\n                self.publish_plan_status("Plan generated and published")\r\n            else:\r\n                rospy.logerr("Failed to generate hierarchical plan")\r\n                self.publish_plan_status("Plan generation failed")\r\n                \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Invalid JSON in highlevel task message")\r\n        except KeyError as e:\r\n            rospy.logerr(f"Missing key in task data: {e}")\r\n    \r\n    def generate_hierarchical_plan(self, task_description: str, priority: str = "normal", deadline: Optional[float] = None) > Optional[Dict]:\r\n        """Generate hierarchical plan using GPT4o"""\r\n        # Get environmental context\r\n        context = self.get_environment_context()\r\n        \r\n        # Create detailed prompt for hierarchical planning\r\n        prompt = f"""\r\n        HighLevel Task: {task_description}\r\n        \r\n        Environmental Context: {json.dumps(context, indent=2)}\r\n        \r\n        Robot Capabilities: {json.dumps(self.knowledge_base["robot_capabilities"], indent=2)}\r\n        Object Affordances: {json.dumps(self.knowledge_base["object_affordances"], indent=2)}\r\n        \r\n        Task Priority: {priority}\r\n        Deadline: {deadline if deadline is not None else \'none\'}\r\n        \r\n        Available Task Templates:\r\n         NavigateToObject: move to object, perceive, prepare for manipulation\r\n         GraspObject: approach, grasp, verify grip\r\n         PlaceObject: navigate, place, verify placement\r\n         OpenContainer: locate, approach, open, verify\r\n         CloseContainer: locate, approach, close, verify\r\n         InspectArea: perceive, analyze, report\r\n         TransportObject: pick, navigate, place\r\n         SetUpWorkspace: arrange objects, prepare area\r\n         CleanUpWorkspace: collect, organize, store\r\n        \r\n        Generate a hierarchical task network that:\r\n        1. Decomposes the highlevel task into intermediate subtasks\r\n        2. Further decomposes subtasks into primitive actions\r\n        3. Considers object affordances and spatial relationships\r\n        4. Respects robot capabilities and constraints\r\n        5. Includes temporal dependencies and resource requirements\r\n        6. Provides fallback strategies for failure recovery\r\n        \r\n        Return the plan in JSON format:\r\n        {{\r\n          "task_id": "unique_identifier",\r\n          "task_description": "{task_description}",\r\n          "priority": "{priority}",\r\n          "deadline": {deadline if deadline is not None else \'null\'},\r\n          "hierarchy": {{\r\n            "level_1": [  // Highlevel objectives\r\n              {{\r\n                "id": "L1_1",\r\n                "name": "subtask_name",\r\n                "description": "what this subtask achieves",\r\n                "dependencies": ["L1_0_previous_task_id"],  // Task dependencies\r\n                "resources_required": ["navigation", "manipulation"],\r\n                "estimated_duration": 30.0,\r\n                "confidence": 0.8\r\n              }}\r\n            ],\r\n            "level_2": [  // Action sequences for each level 1 task\r\n              {{\r\n                "id": "L2_1",\r\n                "parent_id": "L1_1",\r\n                "name": "action_sequence_name",\r\n                "description": "sequence of actions",\r\n                "actions": [  // Primitive actions\r\n                  {{\r\n                    "id": "A1",\r\n                    "type": "navigatge_to_object|grasp_object|place_object|etc.",\r\n                    "parameters": {{"object": "name", "location": "coordinate"}},\r\n                    "preconditions": ["robot_free", "object_visible"],\r\n                    "effects": ["robot_at_location", "object_grasped"],\r\n                    "estimated_duration": 10.0,\r\n                    "probability_of_success": 0.95\r\n                  }}\r\n                ],\r\n                "ordered": true,  // Whether actions must be executed in sequence\r\n                "parallelizable": false,  // Whether actions can run in parallel\r\n                "synchronization_points": ["A3"]  // Actions that require synchronization\r\n              }}\r\n            ]\r\n          }},\r\n          "execution_order": ["L1_1", "L1_2"],  // Order of level 1 tasks\r\n          "resource_schedule": {{\r\n            "navigation": ["L2_1", "L2_3"],\r\n            "manipulation": ["L2_2"],\r\n            "perception": ["L2_1", "L2_2"]\r\n          }},\r\n          "risk_assessment": [\r\n            {{"risk": "object_not_found", "probability": 0.1, "mitigation": "search_alternatives"}},\r\n            {{"risk": "grasp_failure", "probability": 0.05, "mitigation": "retry_different_grasp"}}\r\n          ],\r\n          "success_criteria": [\r\n            "primary_object_placed_correctly",\r\n            "workspace_cleaned_up"\r\n          ],\r\n          "validation_checks": [\r\n            "precondition_verification",\r\n            "intermediate_state_checking",\r\n            "final_state_verification"\r\n          ],\r\n          "estimated_total_duration": 120.0,\r\n          "overall_confidence": 0.7\r\n        }}\r\n        \r\n        Only return the JSON plan, no other text.\r\n        """\r\n        \r\n        try:\r\n            response = self.client.chat.completions.create(\r\n                model=self.model_name,\r\n                messages=[\r\n                    {\r\n                        "role": "system",\r\n                        "content": "You are a hierarchical task planner for robotics. Generate comprehensive hierarchical plans with proper task decomposition, dependencies, and validation. Respond only with valid JSON."\r\n                    },\r\n                    {\r\n                        "role": "user",\r\n                        "content": prompt\r\n                    }\r\n                ],\r\n                temperature=0.1,\r\n                max_tokens=3000\r\n            )\r\n            \r\n            response_text = response.choices[0].message.content.strip()\r\n            \r\n            # Extract JSON from response\r\n            if response_text.startswith(\'```\'):\r\n                start_idx = response_text.find(\'{\')\r\n                end_idx = response_text.rfind(\'}\') + 1\r\n                if start_idx != 1 and end_idx != 1:\r\n                    response_text = response_text[start_idx:end_idx]\r\n            \r\n            plan_data = json.loads(response_text)\r\n            plan_data["timestamp"] = rospy.Time.now().to_sec()\r\n            \r\n            # Validate plan before returning\r\n            if self.validate_hierarchical_plan(plan_data):\r\n                rospy.loginfo(f"Generated hierarchical plan with {len(plan_data[\'hierarchy\'][\'level_1\'])} highlevel tasks")\r\n                return plan_data\r\n            else:\r\n                rospy.logerr("Generated hierarchical plan failed validation")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            rospy.logerr(f"Error generating hierarchical plan: {e}")\r\n            return None\r\n    \r\n    def get_environment_context(self) > Dict:\r\n        """Get current environment context for planning"""\r\n        # In a real implementation, this would come from various ROS topics\r\n        # and might involve querying known object locations, robot state, etc.\r\n        return {\r\n            "robot_state": {\r\n                "current_location": "home_position",\r\n                "battery_level": 0.85,\r\n                "gripper_status": "open",\r\n                "navigation_status": "ready"\r\n            },\r\n            "objects_in_environment": [\r\n                {"name": "coffee_cup", "type": "cup", "location": "kitchen_table", "graspable": True},\r\n                {"name": "water_bottle", "type": "bottle", "location": "desk", "graspable": True},\r\n                {"name": "book", "type": "book", "location": "shelf", "graspable": True},\r\n                {"name": "drawer", "type": "container", "location": "kitchen_counter", "accessible": True, "contents": []}\r\n            ],\r\n            "known_locations": {\r\n                "kitchen_table": {"x": 1.0, "y": 1.0, "theta": 0.0},\r\n                "desk": {"x": 2.0, "y": 0.5, "theta": 0.0},\r\n                "shelf": {"x": 3.0, "y": 1.5, "theta": 0.0},\r\n                "kitchen_counter": {"x": 0.5, "y": 0.8, "theta": 0.0}\r\n            },\r\n            "spatial_constraints": {\r\n                "narrow_corridors": [["kitchen", "office"]],\r\n                "blocked_areas": [],\r\n                "preferred_paths": []\r\n            }\r\n        }\r\n    \r\n    def validate_hierarchical_plan(self, plan: Dict) > bool:\r\n        """Validate hierarchical plan structure"""\r\n        required_fields = ["task_id", "task_description", "hierarchy", "execution_order"]\r\n        hierarchy_required = ["level_1", "level_2"]\r\n        \r\n        # Check toplevel fields\r\n        if not all(field in plan for field in required_fields):\r\n            rospy.logerr("Plan missing required toplevel fields")\r\n            return False\r\n        \r\n        # Check hierarchy structure\r\n        if not all(level in plan["hierarchy"] for level in hierarchy_required):\r\n            rospy.logerr("Plan hierarchy missing required levels")\r\n            return False\r\n        \r\n        # Validate level 1 tasks\r\n        level1_tasks = plan["hierarchy"]["level_1"]\r\n        if not isinstance(level1_tasks, list) or len(level1_tasks) == 0:\r\n            rospy.logerr("No level 1 tasks in hierarchical plan")\r\n            return False\r\n        \r\n        # Validate level 2 sequences\r\n        level2_sequences = plan["hierarchy"]["level_2"]\r\n        if not isinstance(level2_sequences, list):\r\n            rospy.logerr("Level 2 sequences not in list format")\r\n            return False\r\n        \r\n        # Check that level 2 sequences reference valid level 1 parents\r\n        valid_l1_ids = {task["id"] for task in level1_tasks}\r\n        for seq in level2_sequences:\r\n            if seq.get("parent_id") not in valid_l1_ids:\r\n                rospy.logerr(f"Level 2 sequence references invalid parent: {seq.get(\'parent_id\')}")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def publish_hierarchical_plan(self, plan: Dict):\r\n        """Publish the complete hierarchical plan"""\r\n        # Publish highlevel plan\r\n        hl_plan = {\r\n            "task_id": plan["task_id"],\r\n            "tasks": plan["hierarchy"]["level_1"],\r\n            "execution_order": plan["execution_order"],\r\n            "timestamp": plan["timestamp"]\r\n        }\r\n        \r\n        hl_msg = String()\r\n        hl_msg.data = json.dumps(hl_plan, indent=2)\r\n        self.high_level_plan_pub.publish(hl_msg)\r\n        \r\n        # Publish lowlevel plans\r\n        ll_plans = {\r\n            "task_id": plan["task_id"],\r\n            "action_sequences": plan["hierarchy"]["level_2"],\r\n            "resource_schedule": plan["resource_schedule"],\r\n            "timestamp": plan["timestamp"]\r\n        }\r\n        \r\n        ll_msg = String()\r\n        ll_msg.data = json.dumps(ll_plans, indent=2)\r\n        self.low_level_plan_pub.publish(ll_msg)\r\n    \r\n    def add_to_plan_history(self, plan: Dict):\r\n        """Add plan to history with size limiting"""\r\n        self.plan_history.append(plan)\r\n        if len(self.plan_history) > self.max_history_size:\r\n            self.plan_history = self.plan_history[self.max_history_size:]\r\n    \r\n    def publish_plan_status(self, status: str):\r\n        """Publish plan status"""\r\n        status_msg = String()\r\n        status_msg.data = json.dumps({\r\n            "status": status,\r\n            "timestamp": rospy.Time.now().to_sec()\r\n        })\r\n        self.plan_status_pub.publish(status_msg)\r\n    \r\n    def run(self):\r\n        """Run the hierarchical planning node"""\r\n        rospy.loginfo("GPT Hierarchical Planner running...")\r\n        rospy.spin()\r\n\r\ndef main():\r\n    api_key = rospy.get_param(\'~openai_api_key\', \'\')\r\n    if not api_key:\r\n        api_key = input("Enter OpenAI API key: ").strip()\r\n    \r\n    if not api_key:\r\n        rospy.logerr("No OpenAI API key provided!")\r\n        return\r\n    \r\n    planner = GPTHierarchicalPlanner(api_key)\r\n    planner.run()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"lab-3-integrating-with-ros-navigation-stack",children:"Lab 3: Integrating with ROS Navigation Stack"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Create a planning integration node"})," (",(0,a.jsx)(e.code,{children:"planning_integration_node.py"}),"):","\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n\r\nimport rospy\r\nimport actionlib\r\nfrom move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\r\nfrom geometry_msgs.msg import PoseStamped, Twist\r\nfrom std_msgs.msg import String, Bool\r\nfrom sensor_msgs.msg import LaserScan\r\nfrom gpt_planning_interface import GPTPlanningInterface\r\nfrom htn_gpt_planner import GPTHierarchicalPlanner\r\nimport json\r\nimport time\r\nimport threading\r\nimport numpy as np\r\n\r\nclass PlanningIntegrationNode:\r\n    def __init__(self):\r\n        rospy.init_node(\'planning_integration_node\', anonymous=True)\r\n        \r\n        # Initialize planners\r\n        api_key = rospy.get_param(\'~openai_api_key\', \'\')\r\n        if not api_key:\r\n            api_key = input("Enter OpenAI API key: ").strip()\r\n        \r\n        if api_key:\r\n            self.gpt_planner = GPTPlanningInterface(api_key)\r\n            self.htn_planner = GPTHierarchicalPlanner(api_key)\r\n        else:\r\n            rospy.logerr("No API key provided, planners will not be initialized")\r\n        \r\n        # Initialize action clients\r\n        self.move_base_client = actionlib.SimpleActionClient(\'move_base\', MoveBaseAction)\r\n        self.move_base_client.wait_for_server()\r\n        \r\n        # Publishers and Subscribers\r\n        self.nav_goal_pub = rospy.Publisher(\'/move_base_simple/goal\', PoseStamped, queue_size=10)\r\n        self.cmd_vel_pub = rospy.Publisher(\'/cmd_vel\', Twist, queue_size=10)\r\n        rospy.Subscriber(\'/gpt_generated_plan\', String, self.gpt_plan_callback)\r\n        rospy.Subscriber(\'/hl_plan\', String, self.hl_plan_callback)\r\n        rospy.Subscriber(\'/integration_control\', String, self.integration_control_callback)\r\n        rospy.Subscriber(\'/task_request_natural\', String, self.natural_task_callback)\r\n        \r\n        # Internal state\r\n        self.robot_position = PoseStamped()\r\n        self.current_goal = None\r\n        self.plan_execution_active = False\r\n        self.execution_thread = None\r\n        \r\n        rospy.loginfo("Planning Integration Node initialized")\r\n    \r\n    def natural_task_callback(self, msg: String):\r\n        """Handle natural language task requests"""\r\n        task_description = msg.data\r\n        rospy.loginfo(f"Received natural language task: {task_description}")\r\n        \r\n        # Determine if this is a highlevel task or lowlevel command\r\n        if self.is_high_level_task(task_description):\r\n            # Send to hierarchical planner\r\n            hl_task_msg = String()\r\n            hl_task_msg.data = json.dumps({"task": task_description})\r\n            self.high_level_task_pub.publish(hl_task_msg)\r\n        else:\r\n            # Send to GPT planner for direct command processing\r\n            gpt_task_msg = String()\r\n            gpt_task_msg.data = json.dumps({"task": task_description})\r\n            self.gpt_task_pub.publish(gpt_task_msg)\r\n    \r\n    def is_high_level_task(self, description: str) > bool:\r\n        """Determine if a task is highlevel or lowlevel"""\r\n        high_level_keywords = [\r\n            \'arrange\', \'organize\', \'clean\', \'prepare\', \'assist\', \'help\',\r\n            \'bring me\', \'fetch\', \'setup\', \'assemble\', \'construct\', \'repair\',\r\n            \'maintain\', \'monitor\', \'coordinate\', \'manage\', \'plan\', \'schedule\',\r\n            \'organize\'\r\n        ]\r\n        \r\n        low_level_keywords = [\r\n            \'go to\', \'move to\', \'go forward\', \'turn left\', \'turn right\',\r\n            \'stop\', \'halt\', \'navigate\', \'move\', \'go\', \'turn\'\r\n        ]\r\n        \r\n        desc_lower = description.lower()\r\n        \r\n        # Check for highlevel keywords\r\n        if any(kw in desc_lower for kw in high_level_keywords):\r\n            return True\r\n        \r\n        # Check for lowlevel keywords\r\n        if any(kw in desc_lower for kw in low_level_keywords):\r\n            return False\r\n        \r\n        # Default to highlevel for ambiguous tasks\r\n        return True\r\n    \r\n    def gpt_plan_callback(self, msg: String):\r\n        """Handle GPTgenerated plans"""\r\n        try:\r\n            plan_data = json.loads(msg.data)\r\n            rospy.loginfo("Received GPTgenerated plan")\r\n            \r\n            # Execute the plan\r\n            if not self.plan_execution_active:\r\n                self.execute_gpt_plan(plan_data)\r\n            else:\r\n                rospy.logwarn("Plan execution already active, queuing plan...")\r\n                # In a real system, you\'d have a plan queue\r\n                \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Invalid JSON in GPT plan message")\r\n    \r\n    def hl_plan_callback(self, msg: String):\r\n        """Handle hierarchical plans"""\r\n        try:\r\n            hl_plan_data = json.loads(msg.data)\r\n            rospy.loginfo("Received hierarchical plan")\r\n            \r\n            # Execute the hierarchical plan\r\n            if not self.plan_execution_active:\r\n                self.execute_hierarchical_plan(hl_plan_data)\r\n            else:\r\n                rospy.logwarn("Plan execution already active, queuing plan...")\r\n                \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Invalid JSON in hierarchical plan message")\r\n    \r\n    def execute_gpt_plan(self, plan: Dict):\r\n        """Execute a plan generated by GPT"""\r\n        self.plan_execution_active = True\r\n        \r\n        for step in plan.get("steps", []):\r\n            action_type = step["action"]\r\n            parameters = step.get("parameters", {})\r\n            \r\n            rospy.loginfo(f"Executing step: {action_type} with {parameters}")\r\n            \r\n            success = False\r\n            retries = 0\r\n            max_retries = 3\r\n            \r\n            while not success and retries < max_retries:\r\n                if action_type == "navigate":\r\n                    success = self.execute_navigation_step(parameters)\r\n                elif action_type == "manipulate":\r\n                    success = self.execute_manipulation_step(parameters)\r\n                elif action_type == "perceive":\r\n                    success = self.execute_perception_step(parameters)\r\n                elif action_type == "communicate":\r\n                    success = self.execute_communication_step(parameters)\r\n                else:\r\n                    rospy.logwarn(f"Unknown action type: {action_type}")\r\n                    success = True  # Skip unknown actions\r\n                    break\r\n                \r\n                if not success:\r\n                    retries += 1\r\n                    rospy.logwarn(f"Step failed, retrying ({retries}/{max_retries})...")\r\n                    time.sleep(1.0)\r\n            \r\n            if not success:\r\n                rospy.logerr(f"Step failed after {max_retries} retries: {action_type}")\r\n                # Consider plan failure handling\r\n                break\r\n            \r\n            # Check for preconditions before next step\r\n            if not self.verify_preconditions(step.get("preconditions", [])):\r\n                rospy.logerr("Preconditions not met for next step")\r\n                break\r\n        \r\n        self.plan_execution_active = False\r\n        rospy.loginfo("GPT plan execution completed")\r\n    \r\n    def execute_navigation_step(self, params: Dict) > bool:\r\n        """Execute navigation step"""\r\n        target_location = params.get("target_location")\r\n        \r\n        if not target_location:\r\n            rospy.logerr("Navigation step missing target location")\r\n            return False\r\n        \r\n        # Convert target location to coordinates\r\n        target_pose = self.get_location_pose(target_location)\r\n        if not target_pose:\r\n            rospy.logerr(f"Unknown location: {target_location}")\r\n            return False\r\n        \r\n        # Send navigation goal\r\n        goal = MoveBaseGoal()\r\n        goal.target_pose.header.frame_id = "map"\r\n        goal.target_pose.header.stamp = rospy.Time.now()\r\n        goal.target_pose.pose = target_pose\r\n        \r\n        # Send goal to move_base\r\n        self.move_base_client.send_goal(goal)\r\n        \r\n        # Wait for result\r\n        finished_within_time = self.move_base_client.wait_for_result(rospy.Duration(60))  # 1 minute timeout\r\n        \r\n        if not finished_within_time:\r\n            self.move_base_client.cancel_goal()\r\n            rospy.logerr("Navigation timed out")\r\n            return False\r\n        \r\n        state = self.move_base_client.get_state()\r\n        if state == actionlib.GoalStatus.SUCCEEDED:\r\n            rospy.loginfo(f"Successfully navigated to {target_location}")\r\n            return True\r\n        else:\r\n            rospy.logerr(f"Navigation failed with state: {state}")\r\n            return False\r\n    \r\n    def execute_manipulation_step(self, params: Dict) > bool:\r\n        """Execute manipulation step (stub for real manipulation system)"""\r\n        action = params.get("action")\r\n        object_name = params.get("object_name")\r\n        \r\n        rospy.loginfo(f"Manipulation step: {action} {object_name}")\r\n        \r\n        # In a real system, this would interface with manipulation stack\r\n        # For now, simulate completion\r\n        time.sleep(2.0)  # Simulate manipulation time\r\n        \r\n        rospy.loginfo(f"Manipulation step completed: {action} {object_name}")\r\n        return True\r\n    \r\n    def execute_perception_step(self, params: Dict) > bool:\r\n        """Execute perception step (stub for real perception system)"""\r\n        perception_type = params.get("type")\r\n        target_object = params.get("target_object", "unknown")\r\n        \r\n        rospy.loginfo(f"Perception step: {perception_type} {target_object}")\r\n        \r\n        # In a real system, this would trigger perception algorithms\r\n        # For now, simulate perception\r\n        time.sleep(1.0)  # Simulate perception time\r\n        \r\n        rospy.loginfo(f"Perception step completed: {perception_type} {target_object}")\r\n        return True\r\n    \r\n    def execute_communication_step(self, params: Dict) > bool:\r\n        """Execute communication step (stub for real voice system)"""\r\n        message_type = params.get("message_type", "text")\r\n        content = params.get("content", "Hello")\r\n        target = params.get("target_recipient", "operator")\r\n        \r\n        rospy.loginfo(f"Communication step: {message_type} to {target}: {content}")\r\n        \r\n        # In a real system, this would interface with communication stack\r\n        # For now, simulate communication\r\n        time.sleep(0.5)  # Simulate communication time\r\n        \r\n        rospy.loginfo(f"Communication step completed: {content}")\r\n        return True\r\n    \r\n    def get_location_pose(self, location_name: str) > Optional:\r\n        """Get pose for named location"""\r\n        # In real implementation, this would query a location database\r\n        # For now, provide some predefined locations\r\n        locations = {\r\n            "home_position": (0.0, 0.0, 0.0),\r\n            "kitchen": (1.0, 1.0, 0.0),\r\n            "living_room": (2.0, 0.0, 0.0),\r\n            "bedroom": (1.0, 1.0, 0.0),\r\n            "office": (0.0, 2.0, 1.57)\r\n        }\r\n        \r\n        if location_name in locations:\r\n            x, y, theta = locations[location_name]\r\n            pose = Pose()\r\n            pose.position.x = x\r\n            pose.position.y = y\r\n            pose.position.z = 0.0\r\n            \r\n            # Convert theta to quaternion\r\n            from tf.transformations import quaternion_from_euler\r\n            q = quaternion_from_euler(0, 0, theta)\r\n            pose.orientation.x = q[0]\r\n            pose.orientation.y = q[1]\r\n            pose.orientation.z = q[2]\r\n            pose.orientation.w = q[3]\r\n            \r\n            return pose\r\n        else:\r\n            return None\r\n    \r\n    def verify_preconditions(self, preconditions: List[str]) > bool:\r\n        """Verify preconditions are met"""\r\n        for condition in preconditions:\r\n            if condition == "robot_free":\r\n                # Check if robot is not busy\r\n                if self.plan_execution_active:\r\n                    return False\r\n            elif condition == "object_visible":\r\n                # This would require perception system integration\r\n                continue  # For now, assume object is visible\r\n            elif condition == "reachable":\r\n                # This would require path planning verification\r\n                continue  # For now, assume reachable\r\n            elif condition == "graspable":\r\n                # This would require object property verification\r\n                continue  # For now, assume graspable\r\n        \r\n        return True\r\n    \r\n    def integration_control_callback(self, msg: String):\r\n        """Handle integration control commands"""\r\n        command = msg.data.lower()\r\n        \r\n        if command == "execute_plan":\r\n            # This would trigger execution of current plan\r\n            rospy.loginfo("Integration received execute command")\r\n            # Plan execution initiated in other callbacks\r\n        elif command == "cancel_plan":\r\n            # Cancel current plan execution\r\n            self.plan_execution_active = False\r\n            rospy.loginfo("Plan execution cancelled")\r\n            \r\n            # Cancel any active goals\r\n            self.move_base_client.cancel_all_goals()\r\n            \r\n            # Stop robot\r\n            stop_cmd = Twist()\r\n            self.cmd_vel_pub.publish(stop_cmd)\r\n        elif command == "pause_plan":\r\n            rospy.loginfo("Plan execution paused")\r\n            # In real implementation, would pause execution\r\n        elif command == "resume_plan":\r\n            rospy.loginfo("Plan execution resumed")\r\n            # In real implementation, would resume execution\r\n    \r\n    def run(self):\r\n        """Run the integration node"""\r\n        rospy.loginfo("Planning Integration Node running...")\r\n        rospy.spin()\r\n\r\ndef main():\r\n    node = PlanningIntegrationNode()\r\n    node.run()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"runnable-code-example",children:"Runnable Code Example"}),"\n",(0,a.jsx)(e.p,{children:"Here's a complete cognitive planning system that integrates GPT4o with ROS 2:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n# complete_cognitive_planning_system.py\r\n\r\nimport rospy\r\nimport openai\r\nimport json\r\nimport threading\r\nimport queue\r\nfrom std_msgs.msg import String\r\nfrom sensor_msgs.msg import LaserScan\r\nfrom geometry_msgs.msg import Twist, PoseStamped\r\nfrom actionlib_msgs.msg import GoalStatusArray\r\nfrom typing import Dict, List, Optional\r\n\r\nclass CompleteCognitivePlanningSystem:\r\n    def __init__(self, api_key: str):\r\n        rospy.init_node(\'complete_cognitive_planning_system\', anonymous=True)\r\n        \r\n        # Initialize OpenAI client\r\n        self.client = openai.OpenAI(api_key=api_key)\r\n        self.model_name = "gpt4o"\r\n        \r\n        # Publishers\r\n        self.high_level_plan_pub = rospy.Publisher(\'/cognitive/high_level_plan\', String, queue_size=10)\r\n        self.low_level_plan_pub = rospy.Publisher(\'/cognitive/low_level_plan\', String, queue_size=10)\r\n        self.execution_feedback_pub = rospy.Publisher(\'/cognitive/execution_feedback\', String, queue_size=10)\r\n        self.status_pub = rospy.Publisher(\'/cognitive/status\', String, queue_size=10)\r\n        \r\n        # Subscribers\r\n        rospy.Subscriber(\'/cognitive/natural_task\', String, self.natural_task_callback)\r\n        rospy.Subscriber(\'/cognitive/plan_request\', String, self.plan_request_callback)\r\n        rospy.Subscriber(\'/cognitive/execution_status\', String, self.execution_status_callback)\r\n        rospy.Subscriber(\'/scan\', LaserScan, self.laser_callback)\r\n        \r\n        # Internal state\r\n        self.laser_data = None\r\n        self.current_plan = None\r\n        self.plan_queue = queue.Queue()\r\n        self.execution_queue = queue.Queue()\r\n        self.is_executing = False\r\n        \r\n        # System parameters\r\n        self.max_planning_retries = 3\r\n        self.planning_timeout = 30.0\r\n        self.execution_timeout = 60.0\r\n        self.safety_distance = 0.5  # meters\r\n        \r\n        # Knowledge base\r\n        self.initialize_knowledge_base()\r\n        \r\n        self.publish_status("System initialized and ready")\r\n        rospy.loginfo("Complete Cognitive Planning System initialized")\r\n    \r\n    def initialize_knowledge_base(self):\r\n        """Initialize the system\'s knowledge base"""\r\n        self.knowledge_base = {\r\n            "robot_capabilities": {\r\n                "navigation": {\r\n                    "max_linear_speed": 0.5,\r\n                    "max_angular_speed": 1.0,\r\n                    "min_turn_radius": 0.2,\r\n                    "sensor_range": 3.0\r\n                },\r\n                "manipulation": {\r\n                    "max_reach": 0.8,\r\n                    "payload_capacity": 2.0,\r\n                    "gripper_types": ["parallel", "vacuum", "suction"]\r\n                },\r\n                "perception": {\r\n                    "camera_fov": 60.0,  # degrees\r\n                    "depth_range": [0.1, 5.0],  # meters\r\n                    "object_detection_range": [0.2, 3.0]  # meters\r\n                }\r\n            },\r\n            "environment_constraints": [\r\n                "avoid_dynamic_obstacles",\r\n                "maintain_personal_space",\r\n                "respect_doorways",\r\n                "avoid_steep_slopes",\r\n                "stay_on_navigable_surfaces"\r\n            ],\r\n            "task_templates": {\r\n                "navigation": {\r\n                    "actions": ["navigate_to", "explore", "follow_path"],\r\n                    "constraints": ["collision_free", "reachable", "safe_speed"]\r\n                },\r\n                "manipulation": {\r\n                    "actions": ["pick_and_place", "grasp_object", "transport"],\r\n                    "constraints": ["reachable", "graspable", "stable_grasp"]\r\n                },\r\n                "perception": {\r\n                    "actions": ["detect_object", "localize_person", "inspect_area"],\r\n                    "constraints": ["visible", "in_field_of_view", "sufficient_lighting"]\r\n                }\r\n            }\r\n        }\r\n    \r\n    def laser_callback(self, msg: LaserScan):\r\n        """Update laser data for safety checks"""\r\n        self.laser_data = msg\r\n    \r\n    def natural_task_callback(self, msg: String):\r\n        """Handle natural language task requests"""\r\n        try:\r\n            # Parse the task request\r\n            if msg.data.startswith(\'{\'):\r\n                task_request = json.loads(msg.data)\r\n                task_description = task_request["task"]\r\n                priority = task_request.get("priority", "normal")\r\n            else:\r\n                task_description = msg.data\r\n                priority = "normal"\r\n            \r\n            rospy.loginfo(f"Received natural task: {task_description} (Priority: {priority})")\r\n            \r\n            # Validate task request\r\n            if not self.validate_task_request(task_description):\r\n                feedback = {\r\n                    "task_id": "unknown",\r\n                    "status": "invalid_request",\r\n                    "message": "Task request could not be understood",\r\n                    "timestamp": rospy.Time.now().to_sec()\r\n                }\r\n                self.publish_execution_feedback(feedback)\r\n                return\r\n            \r\n            # Add to planning queue\r\n            self.plan_queue.put({\r\n                "task": task_description,\r\n                "priority": priority,\r\n                "request_time": rospy.Time.now().to_sec()\r\n            })\r\n            \r\n            self.publish_status(f"Task received and queued for planning: {task_description[:50]}...")\r\n            \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Invalid JSON in task request")\r\n            self.publish_feedback("Invalid task request format", level="error")\r\n        except KeyError as e:\r\n            rospy.logerr(f"Missing key in task request: {e}")\r\n    \r\n    def validate_task_request(self, task_description: str) > bool:\r\n        """Validate if the task request is understandable"""\r\n        # Basic validation  ensure it has content and isn\'t too generic\r\n        if not task_description or len(task_description.strip()) < 3:\r\n            return False\r\n        \r\n        # Check if it contains actionable verbs\r\n        actionable_verbs = [\r\n            \'move\', \'navigate\', \'go\', \'drive\', \'turn\', \'rotate\',  # movement\r\n            \'pick\', \'grasp\', \'grab\', \'take\', \'place\', \'put\', \'release\',  # manipulation\r\n            \'find\', \'locate\', \'detect\', \'see\', \'look\', \'inspect\',  # perception\r\n            \'tell\', \'say\', \'speak\', \'inform\', \'notify\',  # communication\r\n            \'help\', \'assist\', \'fetch\', \'bring\'  # complex tasks\r\n        ]\r\n        \r\n        task_lower = task_description.lower()\r\n        has_actionable_verb = any(verb in task_lower for verb in actionable_verbs)\r\n        \r\n        # Basic check  task should contain at least one actionable verb\r\n        return has_actionable_verb\r\n    \r\n    def plan_request_callback(self, msg: String):\r\n        """Handle direct plan requests"""\r\n        try:\r\n            plan_request = json.loads(msg.data)\r\n            task_description = plan_request["task"]\r\n            \r\n            # Generate plan directly\r\n            plan = self.generate_cognitive_plan(task_description)\r\n            \r\n            if plan:\r\n                self.publish_hierarchical_plan(plan)\r\n                self.publish_status(f"Plan generated for: {task_description[:30]}...")\r\n            else:\r\n                self.publish_status(f"Plan generation failed for: {task_description[:30]}...")\r\n                \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Invalid JSON in plan request")\r\n    \r\n    def execution_status_callback(self, msg: String):\r\n        """Handle execution status updates"""\r\n        try:\r\n            status = json.loads(msg.data)\r\n            \r\n            # Update internal execution state\r\n            if status.get("status") == "completed":\r\n                self.is_executing = False\r\n                self.publish_status("Plan execution completed")\r\n            elif status.get("status") == "failed":\r\n                self.is_executing = False\r\n                self.publish_status(f"Plan execution failed: {status.get(\'error\', \'Unknown error\')}")\r\n                # Handle failure  maybe generate recovery plan\r\n                self.handle_execution_failure(status)\r\n            elif status.get("status") == "executing":\r\n                self.is_executing = True\r\n                self.publish_status(f"Executing plan: {status.get(\'task_id\', \'unknown\')}")\r\n                \r\n        except json.JSONDecodeError:\r\n            rospy.logerr("Invalid JSON in execution status")\r\n    \r\n    def handle_execution_failure(self, status: Dict):\r\n        """Handle plan execution failures"""\r\n        task_id = status.get("task_id", "unknown")\r\n        error = status.get("error", "Unknown error")\r\n        \r\n        rospy.logwarn(f"Handling failure for task {task_id}: {error}")\r\n        \r\n        # Generate recovery plan if possible\r\n        recovery_plan = self.generate_recovery_plan(task_id, error)\r\n        \r\n        if recovery_plan:\r\n            rospy.loginfo("Recovery plan generated, publishing...")\r\n            self.publish_hierarchical_plan(recovery_plan)\r\n            self.publish_execution_feedback({\r\n                "task_id": task_id,\r\n                "status": "recovery_plan_generated",\r\n                "message": "Recovery plan published",\r\n                "timestamp": rospy.Time.now().to_sec()\r\n            })\r\n        else:\r\n            rospy.logerr("Could not generate recovery plan")\r\n            self.publish_execution_feedback({\r\n                "task_id": task_id,\r\n                "status": "recovery_failed",\r\n                "message": "Could not generate recovery plan",\r\n                "timestamp": rospy.Time.now().to_sec()\r\n            })\r\n    \r\n    def generate_recovery_plan(self, task_id: str, error: str) > Optional[Dict]:\r\n        """Generate a recovery plan after execution failure"""\r\n        # In a real system, this would have access to full plan and error context\r\n        # For now, create a simple recovery strategy\r\n        \r\n        prompt = f"""\r\n        Original Task: {self.current_plan.get(\'task_description\', \'unknown\') if self.current_plan else \'unknown\'}\r\n        Error Encountered: {error}\r\n        Current Environment Context: {json.dumps(self.get_environment_context(), indent=2)}\r\n        \r\n        Available Recovery Strategies:\r\n         Retry: Attempt the same action with different parameters\r\n         Alternative: Use a different approach to achieve the same goal\r\n         Abort: Cancel the task and return to safe state\r\n         Ask for Help: Request human intervention\r\n        \r\n        Generate a recovery plan that addresses the specific failure and attempts to continue task completion.\r\n        Provide the plan in the same format as the original plan generation.\r\n        """\r\n        \r\n        try:\r\n            response = self.client.chat.completions.create(\r\n                model=self.model_name,\r\n                messages=[\r\n                    {\r\n                        "role": "system",\r\n                        "content": "You are a robot task recovery planner. Generate recovery plans that address specific failures and attempt task continuation. Respond only with valid JSON."\r\n                    },\r\n                    {\r\n                        "role": "user",\r\n                        "content": prompt\r\n                    }\r\n                ],\r\n                temperature=0.2,\r\n                max_tokens=1500\r\n            )\r\n            \r\n            response_text = response.choices[0].message.content.strip()\r\n            \r\n            if response_text.startswith(\'```\'):\r\n                start_idx = response_text.find(\'{\')\r\n                end_idx = response_text.rfind(\'}\') + 1\r\n                if start_idx != 1 and end_idx != 1:\r\n                    response_text = response_text[start_idx:end_idx]\r\n            \r\n            recovery_plan = json.loads(response_text)\r\n            recovery_plan["task_id"] = f"{task_id}_recovery"\r\n            recovery_plan["timestamp"] = rospy.Time.now().to_sec()\r\n            \r\n            return recovery_plan\r\n            \r\n        except Exception as e:\r\n            rospy.logerr(f"Error generating recovery plan: {e}")\r\n            return None\r\n    \r\n    def generate_cognitive_plan(self, task_description: str) > Optional[Dict]:\r\n        """Generate cognitive plan using GPT4o"""\r\n        # Get environment context\r\n        context = self.get_environment_context()\r\n        \r\n        # Create detailed planning prompt\r\n        prompt = f"""\r\n        Task: {task_description}\r\n        \r\n        Environment Context: {json.dumps(context, indent=2)}\r\n        \r\n        Robot Capabilities: {json.dumps(self.knowledge_base["robot_capabilities"], indent=2)}\r\n        Task Templates: {json.dumps(self.knowledge_base["task_templates"], indent=2)}\r\n        Environment Constraints: {json.dumps(self.knowledge_base["environment_constraints"], indent=2)}\r\n        \r\n        Available Actions:\r\n        Navigation Actions:\r\n         move_to_location(location_name): Navigate to named location\r\n         navigate_to_object(object_name): Navigate to object position\r\n         avoid_obstacles(): Execute obstacle avoidance\r\n         follow_path(waypoints): Follow sequence of coordinates\r\n         patrol_area(area_name): Navigate through predefined area\r\n        \r\n        Manipulation Actions:\r\n         grasp_object(object_name): Grasp specified object\r\n         place_object(object_name, location): Place object at location  \r\n         transport_object(object_name, from_location, to_location): Move object between locations\r\n         open_container(container_name): Open container/drawer/door\r\n         close_container(container_name): Close container/drawer/door\r\n         handover_object(person_name): Give object to person\r\n        \r\n        Perception Actions:\r\n         detect_object(object_type): Detect object in environment\r\n         recognize_object(object_instance): Confirm identity of object\r\n         localize_person(person_name): Find specific person\r\n         inspect_object(object_name): Examine object state\r\n         scan_area(area_name): Survey area for information\r\n        \r\n        Communication Actions:\r\n         speak_text(text): Speak text aloud\r\n         play_sound(sound_name): Play predefined sound\r\n         send_notification(message): Send message to operator\r\n         request_confirmation(question): Ask for human confirmation\r\n        \r\n        Generate a comprehensive cognitive plan that:\r\n        1. Decomposes the highlevel task into a hierarchical structure\r\n        2. Considers environmental context and safety constraints\r\n        3. Respects robot capabilities and limitations\r\n        4. Includes precondition checking before each step\r\n        5. Provides expected outcomes for verification\r\n        6. Incorporates contingency plans for common failures\r\n        7. Estimates execution time and confidence levels\r\n        \r\n        Return in JSON format:\r\n        {{\r\n          "task_id": "unique_identifier_based_on_time",\r\n          "task_description": "{task_description}",\r\n          "plan_type": "cognitive_task_plan",\r\n          "plan_hierarchy": {{\r\n            "high_level_tasks": [\r\n              {{\r\n                "id": "HL_1",\r\n                "name": "task_name",\r\n                "description": "what this highlevel task accomplishes",\r\n                "dependencies": ["HL_0"],  // Other highlevel tasks this depends on\r\n                "subtasks": ["ST_1_1", "ST_1_2"],  // Subtask IDs that comprise this task\r\n                "estimated_duration": 30.0,\r\n                "confidence": 0.85,\r\n                "success_criteria": ["criteria1", "criteria2"]\r\n              }}\r\n            ],\r\n            "subtasks": [\r\n              {{\r\n                "id": "ST_1_1",\r\n                "parent_id": "HL_1",\r\n                "action_type": "navigation|manipulation|perception|communication",\r\n                "action": "specific_action_name",\r\n                "parameters": {{"param1": "value1", "param2": "value2"}},\r\n                "description": "detailed description of this step",\r\n                "preconditions": [\r\n                  "robot_free", \r\n                  "target_visible", \r\n                  "safety_clear", \r\n                  "resources_available"\r\n                ],\r\n                "expected_effects": [\r\n                  "robot_at_location",\r\n                  "object_detected",\r\n                  "task_step_complete"\r\n                ],\r\n                "success_verification": [\r\n                  "check_robot_pose",\r\n                  "verify_object_state",\r\n                  "confirm_completion"\r\n                ],\r\n                "failure_recovery": [\r\n                  "retry_step",\r\n                  "use_alternative_approach",\r\n                  "abort_task"\r\n                ],\r\n                "estimated_duration": 10.0,\r\n                "success_probability": 0.9\r\n              }}\r\n            ]\r\n          }},\r\n          "execution_schema": {{\r\n            "parallelizable_steps": [["ST_1_1", "ST_1_2"]],  // Steps that can run in parallel\r\n            "synchronization_points": ["ST_1_3"],  // Points where parallel steps must synchronize\r\n            "critical_path": ["ST_0_1", "ST_0_2", "ST_0_3"]  // Sequence that determines total duration\r\n          }},\r\n          "safety_checks": [\r\n            "validate_navigation_path",\r\n            "check_manipulation_feasibility",\r\n            "verify_perception_reliability"\r\n          ],\r\n          "resource_utilization": {{\r\n            "navigation": ["time", "battery"],\r\n            "manipulation": ["time", "gripper", "power"],\r\n            "perception": ["time", "compute", "sensors"],\r\n            "communication": ["time", "bandwidth"]\r\n          }},\r\n          "estimated_total_duration": 120.0,\r\n          "overall_confidence": 0.75,\r\n          "risk_assessment": [\r\n            {{"risk": "object_not_found", "likelihood": 0.1, "impact": "medium", "mitigation": "search_alternatives"}},\r\n            {{"risk": "navigation_failure", "likelihood": 0.05, "impact": "high", "mitigation": "replan_path"}},\r\n            {{"risk": "grasp_failure", "likelihood": 0.08, "impact": "low", "mitigation": "retry_different_grasp"}}\r\n          ],\r\n          "validation_procedures": [\r\n            "pre_execution_checklist",\r\n            "during_execution_monitoring",\r\n            "post_execution_verification"\r\n          ],\r\n          "timestamp": current_timestamp\r\n        }}\r\n        \r\n        Only return the JSON plan with no additional text.\r\n        """\r\n        \r\n        try:\r\n            response = self.client.chat.completions.create(\r\n                model=self.model_name,\r\n                messages=[\r\n                    {\r\n                        "role": "system",\r\n                        "content": "You are an advanced robotic cognitive task planner. Generate detailed, executable plans that consider all constraints, capabilities, and environmental factors. Respond only with valid JSON."\r\n                    },\r\n                    {\r\n                        "role": "user",\r\n                        "content": prompt\r\n                    }\r\n                ],\r\n                temperature=0.1,\r\n                max_tokens=2500\r\n            )\r\n            \r\n            response_text = response.choices[0].message.content.strip()\r\n            \r\n            if response_text.startswith(\'```\'):\r\n                start_idx = response_text.find(\'{\')\r\n                end_idx = response_text.rfind(\'}\') + 1\r\n                if start_idx != 1 and end_idx != 1:\r\n                    response_text = response_text[start_idx:end_idx]\r\n            \r\n            plan_data = json.loads(response_text)\r\n            plan_data["timestamp"] = rospy.Time.now().to_sec()\r\n            \r\n            # Validate the generated plan\r\n            if self.validate_plan_structure(plan_data):\r\n                rospy.loginfo(f"Generated cognitive plan with {len(plan_data[\'plan_hierarchy\'][\'subtasks\'])} steps")\r\n                return plan_data\r\n            else:\r\n                rospy.logerr("Generated plan failed structural validation")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            rospy.logerr(f"Error generating cognitive plan: {e}")\r\n            return None\r\n    \r\n    def get_environment_context(self) > Dict:\r\n        """Get current environment context for planning"""\r\n        context = {\r\n            "robot_state": {\r\n                "position": {"x": 0.0, "y": 0.0, "theta": 0.0},  # Would come from TF or localization\r\n                "status": "idle",\r\n                "battery_level": 0.85,\r\n                "gripper_status": "open",\r\n                "navigation_status": "ready"\r\n            },\r\n            "sensed_environment": {\r\n                "objects": [\r\n                    {"name": "table_1", "type": "furniture", "position": {"x": 1.0, "y": 0.0}, "reachable": True},\r\n                    {"name": "book", "type": "object", "position": {"x": 1.1, "y": 0.1}, "graspable": True},\r\n                    {"name": "chair", "type": "furniture", "position": {"x": 0.0, "y": 1.0}, "reachable": True}\r\n                ],\r\n                "obstacles": self.laser_data.ranges[:50] if self.laser_data else [],  # Sample of front detection\r\n                "safe_zones": ["home_area", "charging_area"],\r\n                "forbidden_zones": []\r\n            },\r\n            "known_locations": {\r\n                "kitchen": {"x": 2.0, "y": 1.0, "theta": 0.0},\r\n                "living_room": {"x": 1.0, "y": 1.0, "theta": 0.0},\r\n                "bedroom": {"x": 1.0, "y": 0.5, "theta": 1.57},\r\n                "office": {"x": 0.0, "y": 2.0, "theta": 3.14},\r\n                "home_position": {"x": 0.0, "y": 0.0, "theta": 0.0},\r\n                "charging_station": {"x": 2.0, "y": 2.0, "theta": 0.0}\r\n            },\r\n            "time_context": {\r\n                "hour_of_day": 14,  # Current hour (24hour format)\r\n                "day_of_week": "tuesday",\r\n                "month": "december"\r\n            },\r\n            "user_preferences": {\r\n                "preferred_speed": "moderate",\r\n                "safety_preference": "conservative",\r\n                "interaction_mode": "autonomous"\r\n            }\r\n        }\r\n        \r\n        return context\r\n    \r\n    def validate_plan_structure(self, plan: Dict) > bool:\r\n        """Validate the structure of a generated plan"""\r\n        required_fields = [\r\n            "task_id", "task_description", "plan_hierarchy", \r\n            "estimated_total_duration", "overall_confidence"\r\n        ]\r\n        \r\n        if not all(field in plan for field in required_fields):\r\n            rospy.logerr("Plan missing required toplevel fields")\r\n            return False\r\n        \r\n        hierarchy = plan.get("plan_hierarchy", {})\r\n        required_hierarchy = ["high_level_tasks", "subtasks"]\r\n        \r\n        if not all(field in hierarchy for field in required_hierarchy):\r\n            rospy.logerr("Plan hierarchy missing required components")\r\n            return False\r\n        \r\n        # Validate that subtasks reference valid highlevel tasks\r\n        hl_task_ids = {task["id"] for task in hierarchy["high_level_tasks"]}\r\n        for subtask in hierarchy["subtasks"]:\r\n            parent_id = subtask.get("parent_id")\r\n            if parent_id and parent_id not in hl_task_ids:\r\n                rospy.logerr(f"Subtask {subtask.get(\'id\')} references invalid parent {parent_id}")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def publish_hierarchical_plan(self, plan: Dict):\r\n        """Publish the complete hierarchical plan"""\r\n        # Split plan into highlevel and lowlevel components for different consumers\r\n        high_level = {\r\n            "task_id": plan["task_id"],\r\n            "task_description": plan["task_description"],\r\n            "high_level_tasks": plan["plan_hierarchy"]["high_level_tasks"],\r\n            "execution_schema": plan["execution_schema"],\r\n            "timestamp": plan["timestamp"]\r\n        }\r\n        \r\n        low_level = {\r\n            "task_id": plan["task_id"],\r\n            "subtasks": plan["plan_hierarchy"]["subtasks"],\r\n            "safety_checks": plan["safety_checks"],\r\n            "execution_schema": plan["execution_schema"],\r\n            "timestamp": plan["timestamp"]\r\n        }\r\n        \r\n        # Publish highlevel plan\r\n        hl_msg = String()\r\n        hl_msg.data = json.dumps(high_level, indent=2)\r\n        self.high_level_plan_pub.publish(hl_msg)\r\n        \r\n        # Publish lowlevel plan\r\n        ll_msg = String()\r\n        ll_msg.data = json.dumps(low_level, indent=2)\r\n        self.low_level_plan_pub.publish(ll_msg)\r\n    \r\n    def publish_execution_feedback(self, feedback: Dict):\r\n        """Publish execution feedback"""\r\n        feedback_msg = String()\r\n        feedback_msg.data = json.dumps(feedback, indent=2)\r\n        self.execution_feedback_pub.publish(feedback_msg)\r\n    \r\n    def publish_status(self, status: str):\r\n        """Publish system status"""\r\n        status_msg = String()\r\n        status_msg.data = json.dumps({\r\n            "status": status,\r\n            "timestamp": rospy.Time.now().to_sec()\r\n        })\r\n        self.status_pub.publish(status_msg)\r\n    \r\n    def run(self):\r\n        """Run the cognitive planning system"""\r\n        rospy.loginfo("Starting Complete Cognitive Planning System...")\r\n        \r\n        # Start planning thread for processing queued requests\r\n        planning_thread = threading.Thread(target=self.planning_loop)\r\n        planning_thread.daemon = True\r\n        planning_thread.start()\r\n        \r\n        rospy.spin()\r\n    \r\n    def planning_loop(self):\r\n        """Process planning requests in a separate thread"""\r\n        rate = rospy.Rate(1)  # 1 Hz polling of plan queue\r\n        \r\n        while not rospy.is_shutdown():\r\n            try:\r\n                # Get next planning request\r\n                request = self.plan_queue.get(timeout=1.0)\r\n                \r\n                # Generate plan\r\n                plan = self.generate_cognitive_plan(request["task"])\r\n                \r\n                if plan:\r\n                    self.current_plan = plan\r\n                    self.publish_hierarchical_plan(plan)\r\n                    \r\n                    feedback = {\r\n                        "task_id": plan["task_id"],\r\n                        "status": "plan_generated",\r\n                        "message": "Cognitive plan successfully generated",\r\n                        "timestamp": rospy.Time.now().to_sec()\r\n                    }\r\n                else:\r\n                    # Plan generation failed\r\n                    feedback = {\r\n                        "task_id": "unknown",  # Can\'t generate ID without plan\r\n                        "status": "generation_failed",\r\n                        "message": "Cognitive plan generation failed",\r\n                        "request_task": request["task"],\r\n                        "timestamp": rospy.Time.now().to_sec()\r\n                    }\r\n                \r\n                self.publish_execution_feedback(feedback)\r\n                self.plan_queue.task_done()\r\n                \r\n            except queue.Empty:\r\n                continue\r\n            except Exception as e:\r\n                rospy.logerr(f"Error in planning loop: {e}")\r\n                continue\r\n            \r\n            rate.sleep()\r\n\r\ndef main():\r\n    api_key = rospy.get_param(\'~openai_api_key\', \'\')\r\n    if not api_key:\r\n        api_key = input("Enter OpenAI API key: ").strip()\r\n    \r\n    if not api_key:\r\n        rospy.logerr("No OpenAI API key provided!")\r\n        return\r\n    \r\n    system = CompleteCognitivePlanningSystem(api_key)\r\n    system.run()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(e.h3,{id:"launch-file-for-the-system",children:"Launch file for the system:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<launch>\r\n  <! Complete Cognitive Planning System >\r\n  <node name="complete_cognitive_planner" pkg="robot_planning" type="complete_cognitive_planning_system.py" output="screen">\r\n    <param name="openai_api_key" value=""/>\r\n    <param name="safety_distance" value="0.5"/>\r\n    <param name="max_planning_retries" value="3"/>\r\n  </node>\r\n  \r\n  <! Example: Simple robot simulation for testing >\r\n  <include file="$(find turtlebot3_gazebo)/launch/turtlebot3_empty_world.launch"/>\r\n  \r\n  <! TF for robot >\r\n  <node name="robot_state_publisher" pkg="robot_state_publisher" type="robot_state_publisher"/>\r\n  \r\n  <! Joint state publisher for simulated joints >\r\n  <node name="joint_state_publisher" pkg="joint_state_publisher" type="joint_state_publisher">\r\n    <param name="use_gui" value="false"/>\r\n  </node>\r\n</launch>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"miniproject",children:"Miniproject"}),"\n",(0,a.jsx)(e.p,{children:"Create a complete cognitive planning system that:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Implements GPT4obased task decomposition for complex robotic missions"}),"\n",(0,a.jsx)(e.li,{children:"Integrates with ROS navigation stack for execution"}),"\n",(0,a.jsx)(e.li,{children:"Creates hierarchical task networks with multiple abstraction levels"}),"\n",(0,a.jsx)(e.li,{children:"Implements plan monitoring and execution feedback"}),"\n",(0,a.jsx)(e.li,{children:"Handles multirobot coordination scenarios"}),"\n",(0,a.jsx)(e.li,{children:"Evaluates plan success and provides learning feedback"}),"\n",(0,a.jsx)(e.li,{children:"Implements safety validation for all generated plans"}),"\n",(0,a.jsx)(e.li,{children:"Creates a visualization interface for plan monitoring"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Your project should include:\r\nComplete GPT4o integration for task planning\r\nHierarchical task network generation\r\nROS integration for plan execution\r\nMultirobot coordination mechanisms\r\nSafety validation system\r\nPlan monitoring and feedback mechanisms\r\nPerformance evaluation metrics\r\nVisualization interface"}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"This chapter covered cognitive task planning with GPT4o:"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Multimodal Integration"}),": Fusing information from different sensor modalities\r\n",(0,a.jsx)(e.strong,{children:"Early vs Late Fusion"}),": Different approaches to combining sensor data\r\n",(0,a.jsx)(e.strong,{children:"Deep Fusion"}),": Learnable fusion within neural network architectures\r\n",(0,a.jsx)(e.strong,{children:"Transformerbased Fusion"}),": Attention mechanisms for multimodal integration\r\n",(0,a.jsx)(e.strong,{children:"Sensor Calibration"}),": Ensuring proper alignment between modalities\r\n",(0,a.jsx)(e.strong,{children:"Synchronization"}),": Aligning temporal data from different sensors\r\n",(0,a.jsx)(e.strong,{children:"Fusion Algorithms"}),": Techniques for combining multimodal information\r\n",(0,a.jsx)(e.strong,{children:"Uncertainty Handling"}),": Managing uncertainty in fused perceptual data\r\n",(0,a.jsx)(e.strong,{children:"Performance Evaluation"}),": Metrics for assessing fusion effectiveness"]}),"\n",(0,a.jsx)(e.p,{children:"Multimodal perception fusion enables robots to develop a more comprehensive understanding of their environment by combining complementary information from multiple sensors. This results in more robust and accurate perception systems that can handle challenging conditions where individual sensors may fail."})]})}function d(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(_,{...n})}):_(n)}}}]);