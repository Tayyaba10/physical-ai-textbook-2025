"use strict";(globalThis.webpackChunkai_native_robotics_textbook=globalThis.webpackChunkai_native_robotics_textbook||[]).push([[7759],{2522:(r,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>l,default:()=>d,frontMatter:()=>t,metadata:()=>a,toc:()=>_});const a=JSON.parse('{"id":"module-3-ai-robot-brain/ch13-isaac-ros-accelerated-vslam","title":"ch13-isaac-ros-accelerated-vslam","description":"-----","source":"@site/docs/module-3-ai-robot-brain/ch13-isaac-ros-accelerated-vslam.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/ch13-isaac-ros-accelerated-vslam","permalink":"/physical-ai-textbook-2025/docs/module-3-ai-robot-brain/ch13-isaac-ros-accelerated-vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/Tayyaba10/physical-ai-textbook-2025/edit/main/docs/module-3-ai-robot-brain/ch13-isaac-ros-accelerated-vslam.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docs","previous":{"title":"ch12-isaac-sim-photorealistic","permalink":"/physical-ai-textbook-2025/docs/module-3-ai-robot-brain/ch12-isaac-sim-photorealistic"},"next":{"title":"ch14-bipedal-locomotion-balance","permalink":"/physical-ai-textbook-2025/docs/module-3-ai-robot-brain/ch14-bipedal-locomotion-balance"}}');var i=n(4848),s=n(8453),o=n(7242);const t={},l=void 0,c={},_=[{value:"title: Ch13  Isaac ROS  HardwareAccelerated VSLAM &amp; Nav2\r\nmodule: 3\r\nchapter: 13\r\nsidebar_label: Ch13: Isaac ROS  HardwareAccelerated VSLAM &amp; Nav2\r\ndescription: Implementing hardwareaccelerated Visual SLAM and navigation with Isaac ROS\r\ntags: [isaacros, slam, navigation, gpuacceleration, vslam, nav2, robotics]\r\ndifficulty: advanced\r\nestimated_duration: 120",id:"title-ch13--isaac-ros--hardwareaccelerated-vslam--nav2module-3chapter-13sidebar_label-ch13-isaac-ros--hardwareaccelerated-vslam--nav2description-implementing-hardwareaccelerated-visual-slam-and-navigation-with-isaac-rostags-isaacros-slam-navigation-gpuacceleration-vslam-nav2-roboticsdifficulty-advancedestimated_duration-120",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Theory",id:"theory",level:2},{value:"Isaac ROS Perception Pipeline Architecture",id:"isaac-ros-perception-pipeline-architecture",level:3},{value:"Visual SLAM in Isaac ROS",id:"visual-slam-in-isaac-ros",level:3},{value:"GPU Acceleration Benefits",id:"gpu-acceleration-benefits",level:3},{value:"Isaac ROS vs Standard ROS 2",id:"isaac-ros-vs-standard-ros-2",level:3},{value:"StepbyStep Labs",id:"stepbystep-labs",level:2},{value:"Lab 1: Installing and Configuring Isaac ROS",id:"lab-1-installing-and-configuring-isaac-ros",level:3},{value:"Lab 2: Setting up Isaac ROS Visual SLAM",id:"lab-2-setting-up-isaac-ros-visual-slam",level:3},{value:"Lab 3: Implementing Isaac ROS with Nav2",id:"lab-3-implementing-isaac-ros-with-nav2",level:3},{value:"Lab 4: Performance Comparison and Optimization",id:"lab-4-performance-comparison-and-optimization",level:3},{value:"Runnable Code Example",id:"runnable-code-example",level:2},{value:"Isaac ROS Launch File for Complete System",id:"isaac-ros-launch-file-for-complete-system",level:3},{value:"Miniproject",id:"miniproject",level:2},{value:"Summary",id:"summary",level:2}];function m(r){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...r.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"title-ch13--isaac-ros--hardwareaccelerated-vslam--nav2module-3chapter-13sidebar_label-ch13-isaac-ros--hardwareaccelerated-vslam--nav2description-implementing-hardwareaccelerated-visual-slam-and-navigation-with-isaac-rostags-isaacros-slam-navigation-gpuacceleration-vslam-nav2-roboticsdifficulty-advancedestimated_duration-120",children:"title: Ch13  Isaac ROS  HardwareAccelerated VSLAM & Nav2\r\nmodule: 3\r\nchapter: 13\r\nsidebar_label: Ch13: Isaac ROS  HardwareAccelerated VSLAM & Nav2\r\ndescription: Implementing hardwareaccelerated Visual SLAM and navigation with Isaac ROS\r\ntags: [isaacros, slam, navigation, gpuacceleration, vslam, nav2, robotics]\r\ndifficulty: advanced\r\nestimated_duration: 120"}),"\n","\n",(0,i.jsx)(e.h1,{id:"isaac-ros--hardwareaccelerated-vslam--nav2",children:"Isaac ROS  HardwareAccelerated VSLAM & Nav2"}),"\n",(0,i.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(e.p,{children:"Implement GPUaccelerated Visual SLAM using Isaac ROS\r\nConfigure and optimize Nav2 with Isaac ROS components\r\nUnderstand the architecture of Isaac ROS perception pipelines\r\nIntegrate Isaac ROS with standard ROS 2 navigation stack\r\nOptimize perception and navigation performance using GPU acceleration\r\nTroubleshoot common issues in Isaac ROS perception systems\r\nEvaluate the performance benefits of hardware acceleration"}),"\n",(0,i.jsx)(e.h2,{id:"theory",children:"Theory"}),"\n",(0,i.jsx)(e.h3,{id:"isaac-ros-perception-pipeline-architecture",children:"Isaac ROS Perception Pipeline Architecture"}),"\n",(0,i.jsx)(e.p,{children:"Isaac ROS provides hardwareaccelerated implementations of common robotics perception algorithms. The architecture is designed to leverage NVIDIA GPU capabilities:"}),"\n",(0,i.jsx)(o.A,{chart:"\ngraph TD;\n  A[Isaac ROS Perception] > B[Image Acquisition];\n  A > C[Image Preprocessing];\n  A > D[Feature Extraction];\n  A > E[SLAM Backend];\n  \n  B > F[Hardware Image Format Conversion];\n  C > G[GPUbased Image Rectification];\n  D > H[CUDAbased Feature Detection];\n  E > I[GPUaccelerated Optimization];\n  \n  J[Isaac ROS Nav2] > K[Costmap Generation];\n  J > L[Path Planning];\n  J > M[Path Following];\n  \n  K > N[GPUbased Obstacle Processing];\n  L > O[Accelerated Path Optimizers];\n  M > P[Model Predictive Control];\n  \n  style A fill:#4CAF50,stroke:#388E3C,color:#fff;\n  style J fill:#2196F3,stroke:#0D47A1,color:#fff;\n  style H fill:#FF9800,stroke:#E65100,color:#fff;\n  style N fill:#9C27B0,stroke:#4A148C,color:#fff;\n"}),"\n",(0,i.jsx)(e.h3,{id:"visual-slam-in-isaac-ros",children:"Visual SLAM in Isaac ROS"}),"\n",(0,i.jsx)(e.p,{children:"Visual SLAM (Simultaneous Localization and Mapping) in Isaac ROS specifically leverages GPU processing for:"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Image Rectification"}),": Accelerated distortion correction\r\n",(0,i.jsx)(e.strong,{children:"Feature Detection"}),": FAST, ORB, and other feature detectors\r\n",(0,i.jsx)(e.strong,{children:"Feature Matching"}),": GPUaccelerated descriptor matching\r\n",(0,i.jsx)(e.strong,{children:"Bundle Adjustment"}),": Optimized pose graph optimization\r\n",(0,i.jsx)(e.strong,{children:"Loop Closure"}),": Accelerated place recognition"]}),"\n",(0,i.jsx)(e.h3,{id:"gpu-acceleration-benefits",children:"GPU Acceleration Benefits"}),"\n",(0,i.jsx)(e.p,{children:"GPU acceleration in Isaac ROS provides significant performance improvements:"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Parallel Processing"}),": Thousands of threads for image processing\r\n",(0,i.jsx)(e.strong,{children:"Memory Bandwidth"}),": Highbandwidth memory for texture/image operations\r\n",(0,i.jsx)(e.strong,{children:"Specialized Units"}),": Tensor cores for deep learning operations\r\n",(0,i.jsx)(e.strong,{children:"Reduced Latency"}),": Realtime processing of sensor data"]}),"\n",(0,i.jsx)(e.h3,{id:"isaac-ros-vs-standard-ros-2",children:"Isaac ROS vs Standard ROS 2"}),"\n",(0,i.jsx)(e.p,{children:"Isaac ROS components are dropin replacements for standard ROS 2 components with GPU acceleration:"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Isaac ROS Image Pipeline"}),": Hardwareaccelerated image processing\r\n",(0,i.jsx)(e.strong,{children:"Isaac ROS VSLAM"}),": GPUaccelerated visual SLAM\r\n",(0,i.jsx)(e.strong,{children:"Isaac ROS Navigation"}),": Optimized navigation algorithms\r\n",(0,i.jsx)(e.strong,{children:"Isaac ROS Sensors"}),": GPUaccelerated sensor processing"]}),"\n",(0,i.jsx)(e.h2,{id:"stepbystep-labs",children:"StepbyStep Labs"}),"\n",(0,i.jsx)(e.h3,{id:"lab-1-installing-and-configuring-isaac-ros",children:"Lab 1: Installing and Configuring Isaac ROS"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Install Isaac ROS packages"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# Add the NVIDIA repository\r\nsudo apt update\r\nsudo apt install y softwarepropertiescommon\r\nsudo addaptrepository r ppa:deadsnakes/ppa  # Remove potential conflicts\r\nsudo apt update\r\n\r\n# Install Isaac ROS packages\r\nsudo apt install y roshumbleisaacroscommon\r\nsudo apt install y roshumbleisaacrosvisualslam\r\nsudo apt install y roshumbleisaacrospointcloudprocessor\r\nsudo apt install y roshumbleisaacrosapriltag\r\nsudo apt install y roshumbleisaacrosgxf\n"})}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Verify GPU is accessible"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"nvidiasmi\r\n# Should show your NVIDIA GPU and driver information\n"})}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Check Isaac ROS installation"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"ros2 pkg list | grep isaac_ros\r\n# Should list Isaac ROS packages\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"lab-2-setting-up-isaac-ros-visual-slam",children:"Lab 2: Setting up Isaac ROS Visual SLAM"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Create a workspace for Isaac ROS SLAM"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"mkdir p ~/isaac_ros_ws/src\r\ncd ~/isaac_ros_ws\n"})}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Create a launch file for Isaac ROS Visual SLAM"})," (",(0,i.jsx)(e.code,{children:"launch/isaac_ros_vslam.launch.py"}),"):"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import os\r\nfrom ament_index_python.packages import get_package_share_directory\r\nfrom launch import LaunchDescription\r\nfrom launch.actions import DeclareLaunchArgument\r\nfrom launch.substitutions import LaunchConfiguration\r\nfrom launch_ros.actions import ComposableNodeContainer\r\nfrom launch_ros.descriptions import ComposableNode\r\n\r\ndef generate_launch_description():\r\n    # Declare launch arguments\r\n    use_sim_time = DeclareLaunchArgument(\r\n        'use_sim_time',\r\n        default_value='false',\r\n        description='Use simulation (Isaac Sim) clock if true'\r\n    )\r\n    \r\n    # Create a composable node container for Isaac ROS VSLAM\r\n    vslam_container = ComposableNodeContainer(\r\n        name='vslam_container',\r\n        namespace='',\r\n        package='rclcpp_components',\r\n        executable='component_container_mt',\r\n        composable_node_descriptions=[\r\n            ComposableNode(\r\n                package='isaac_ros_visual_slam',\r\n                plugin='isaac_ros::visual_slam::VisualSlamNode',\r\n                name='visual_slam',\r\n                parameters=[{\r\n                    'use_sim_time': LaunchConfiguration('use_sim_time'),\r\n                    'enable_debug_mode': False,\r\n                    'debug_dump_path': '/tmp/visual_slam_debug',\r\n                    'enable_slam_visualization': True,\r\n                    'enable_landmarks_view': True,\r\n                    'enable_observations_view': True,\r\n                    'map_frame': 'map',\r\n                    'odom_frame': 'odom',\r\n                    'base_frame': 'base_link',\r\n                    'intra_process_comms': True\r\n                }],\r\n                remappings=[\r\n                    ('/visual_slam/integrated_imu', '/imu'),\r\n                    ('/visual_slam/image_raw', '/camera/image_raw'),\r\n                    ('/visual_slam/camera_info', '/camera/camera_info'),\r\n                    ('/visual_slam/visual_odometry', '/visual_odometry'),\r\n                    ('/visual_slam/tracking/landmarks', '/landmarks'),\r\n                    ('/visual_slam/acceleration', '/accel'),\r\n                    ('/visual_slam/velocity', '/velocity')\r\n                ]\r\n            ),\r\n            \r\n            # Image Rectification node to prepare images for VSLAM\r\n            ComposableNode(\r\n                package='isaac_ros_image_rectifier',\r\n                plugin='nvidia::isaac_ros::image_rectifier::RectifyNode',\r\n                name='image_rectifier_node',\r\n                parameters=[{\r\n                    'use_sim_time': LaunchConfiguration('use_sim_time'),\r\n                    'input_width': 640,\r\n                    'input_height': 480,\r\n                    'output_width': 640,\r\n                    'output_height': 480,\r\n                }],\r\n                remappings=[\r\n                    ('image_raw', '/camera/image_raw'),\r\n                    ('camera_info', '/camera/camera_info'),\r\n                    ('image_rect', '/rectified/image_raw'),\r\n                    ('camera_info_rect', '/rectified/camera_info')\r\n                ]\r\n            )\r\n        ],\r\n        output='screen'\r\n    )\r\n    \r\n    # Add the container to the launch description\r\n    ld = LaunchDescription()\r\n    ld.add_action(use_sim_time)\r\n    ld.add_action(vslam_container)\r\n    \r\n    return ld\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"lab-3-implementing-isaac-ros-with-nav2",children:"Lab 3: Implementing Isaac ROS with Nav2"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Install Nav2 packages"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"sudo apt install y roshumblenavigation2 roshumblenav2bringup\n"})}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Create a Nav2 configuration file"})," (",(0,i.jsx)(e.code,{children:"config/isaac_nav2_params.yaml"}),"):"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:'amcl:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    alpha1: 0.2\r\n    alpha2: 0.2\r\n    alpha3: 0.2\r\n    alpha4: 0.2\r\n    alpha5: 0.2\r\n    base_frame_id: "base_link"\r\n    beam_skip_distance: 0.5\r\n    beam_skip_error_threshold: 0.9\r\n    beam_skip_threshold: 0.3\r\n    do_beamskip: false\r\n    global_frame_id: "map"\r\n    lambda_short: 0.1\r\n    likelihood_max_dist: 2.0\r\n    lod_obstacle_range: 2.5\r\n    max_beams: 60\r\n    max_particles: 2000\r\n    min_particles: 500\r\n    odom_frame_id: "odom"\r\n    pf_err: 0.05\r\n    pf_z: 0.99\r\n    recovery_alpha_fast: 0.0\r\n    recovery_alpha_slow: 0.0\r\n    resample_interval: 1\r\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\r\n    save_pose_rate: 0.5\r\n    sigma_hit: 0.2\r\n    tf_broadcast: true\r\n    transform_tolerance: 1.0\r\n    update_min_a: 0.2\r\n    update_min_d: 0.25\r\n    z_hit: 0.5\r\n    z_max: 0.05\r\n    z_rand: 0.5\r\n    z_short: 0.05\r\n    scan_topic: scan\r\n    set_initial_pose: true\r\n    initial_pose:\r\n      x: 0.0\r\n      y: 0.0\r\n      z: 0.0\r\n      yaw: 0.0\r\n\r\nbt_navigator:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    global_frame: map\r\n    robot_base_frame: base_link\r\n    odom_topic: /odom\r\n    bt_loop_duration: 10\r\n    default_server_timeout: 20\r\n    enable_groot_monitoring: True\r\n    groot_zmq_publisher_port: 1666\r\n    groot_zmq_server_port: 1667\r\n    default_nav_through_poses_bt_xml: navigate_through_poses_w_replanning_and_recovery.xml\r\n    default_nav_to_pose_bt_xml: navigate_to_pose_w_replanning_and_recovery.xml\r\n    plugin_lib_names:\r\n     nav2_compute_path_to_pose_action_bt_node\r\n     nav2_compute_path_through_poses_action_bt_node\r\n     nav2_smooth_path_action_bt_node\r\n     nav2_follow_path_action_bt_node\r\n     nav2_spin_action_bt_node\r\n     nav2_wait_action_bt_node\r\n     nav2_assisted_teleop_action_bt_node\r\n     nav2_back_up_action_bt_node\r\n     nav2_drive_on_heading_bt_node\r\n     nav2_clear_costmap_service_bt_node\r\n     nav2_is_stuck_condition_bt_node\r\n     nav2_goal_reached_condition_bt_node\r\n     nav2_goal_updated_condition_bt_node\r\n     nav2_globally_updated_goal_condition_bt_node\r\n     nav2_is_path_valid_condition_bt_node\r\n     nav2_initial_pose_received_condition_bt_node\r\n     nav2_reinitialize_global_localization_service_bt_node\r\n     nav2_rate_controller_bt_node\r\n     nav2_distance_controller_bt_node\r\n     nav2_speed_controller_bt_node\r\n     nav2_truncate_path_action_bt_node\r\n     nav2_truncate_path_local_action_bt_node\r\n     nav2_goal_updater_node_bt_node\r\n     nav2_recovery_node_bt_node\r\n     nav2_pipeline_sequence_bt_node\r\n     nav2_round_robin_node_bt_node\r\n     nav2_transformer_bt_node\r\n     nav2_get_costmap_node_bt_node\r\n     nav2_get_costmap_expensive_node_bt_node\r\n     nav2_is_battery_low_condition_bt_node\r\n     nav2_navigate_through_poses_action_bt_node\r\n     nav2_navigate_to_pose_action_bt_node\r\n     nav2_remove_passed_goals_action_bt_node\r\n     nav2_planner_selector_bt_node\r\n     nav2_controller_selector_bt_node\r\n     nav2_goal_checker_selector_bt_node\r\n     nav2_controller_cancel_bt_node\r\n     nav2_path_longer_on_approach_bt_node\r\n     nav2_wait_cancel_bt_node\r\n     nav2_spin_cancel_bt_node\r\n     nav2_back_up_cancel_bt_node\r\n     nav2_assisted_teleop_cancel_bt_node\r\n     nav2_drive_on_heading_cancel_bt_node\r\n\r\nbt_navigator_navigate_through_poses_rclcpp_node:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n\r\nbt_navigator_navigate_to_pose_rclcpp_node:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n\r\ncontroller_server:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    controller_frequency: 20.0\r\n    min_x_velocity_threshold: 0.001\r\n    min_y_velocity_threshold: 0.5\r\n    min_theta_velocity_threshold: 0.001\r\n    progress_checker_plugin: "progress_checker"\r\n    goal_checker_plugin: "goal_checker"\r\n    controller_plugins: ["FollowPath"]\r\n    progress_checker:\r\n      plugin: "nav2_controller::SimpleProgressChecker"\r\n      required_movement_radius: 0.5\r\n      movement_time_allowance: 10.0\r\n    goal_checker:\r\n      plugin: "nav2_controller::SimpleGoalChecker"\r\n      xy_goal_tolerance: 0.25\r\n      yaw_goal_tolerance: 0.25\r\n      stateful: True\r\n    FollowPath:\r\n      plugin: "nav2_rotation_shim_controller::RotationShimController"\r\n      primary_controller: "nav2_regulated_pure_pursuit_controller::RegulatedPurePursuitController"\r\n      rotation_shim:\r\n        plugin: "nav2_controller::SimpleGoalChecker"\r\n        xy_goal_tolerance: 0.10\r\n        yaw_goal_tolerance: 0.05\r\n        stateful: True\r\n        rot_stopped_velocity_threshold: 0.10\r\n        trans_stopped_velocity_threshold: 0.10\r\n        simulate_ahead_time: 1.0\r\n        max_allowed_time_to_rotate: 1.0\r\n      regulated_pure_pursuit_controller:\r\n        plugin: "nav2_regulated_pure_pursuit_controller::RegulatedPurePursuitController"\r\n        desired_linear_vel: 0.5\r\n        max_linear_accel: 2.5\r\n        max_linear_decel: 2.5\r\n        desired_angular_vel: 1.5\r\n        max_angular_accel: 3.2\r\n        min_turn_radius: 0.0\r\n        max_lookahead_dist: 1.0\r\n        min_lookahead_dist: 0.3\r\n        lookahead_time: 1.5\r\n        rotate_to_heading_angular_vel: 1.8\r\n        max_angular_accel_for_rotation: 3.2\r\n        use_velocity_scaled_lookahead_dist: false\r\n        min_vel_ratio_for_rotate_to_heading: 0.10\r\n        use_rotate_to_heading: true\r\n        rotate_to_heading_min_angle: 0.5\r\n        waypoint_lookahead_dist: 0.3\r\n        use_interpolation: true\r\n        use_sigmoid_lookahead: false\r\n        use_custom_anthropic_lookahead: false\r\n        path_dist_tolerance: 0.10\r\n        goal_dist_tolerance: 0.10\r\n        transform_tolerance: 0.1\r\n        heading_lookahead_dist: 0.10\r\n        allow_reversing: false\r\n\r\nlocal_costmap:\r\n  local_costmap:\r\n    ros__parameters:\r\n      update_frequency: 5.0\r\n      publish_frequency: 2.0\r\n      global_frame: odom\r\n      robot_base_frame: base_link\r\n      use_sim_time: False\r\n      rolling_window: true\r\n      width: 3\r\n      height: 3\r\n      resolution: 0.05\r\n      robot_radius: 0.22\r\n      plugins: ["voxel_layer", "inflation_layer"]\r\n      inflation_layer:\r\n        plugin: "nav2_costmap_2d::InflationLayer"\r\n        cost_scaling_factor: 3.0\r\n        inflation_radius: 0.55\r\n      voxel_layer:\r\n        plugin: "nav2_costmap_2d::VoxelLayer"\r\n        enabled: True\r\n        publish_voxel_map: False\r\n        origin_z: 0.0\r\n        z_resolution: 0.05\r\n        z_voxels: 16\r\n        max_obstacle_height: 2.0\r\n        mark_threshold: 0\r\n        observation_sources: scan\r\n        scan:\r\n          topic: /scan\r\n          max_obstacle_height: 2.0\r\n          clearing: True\r\n          marking: True\r\n          data_type: "LaserScan"\r\n          raytrace_max_range: 3.0\r\n          raytrace_min_range: 0.0\r\n          obstacle_max_range: 2.5\r\n          obstacle_min_range: 0.0\r\n      static_map_layer:\r\n        map_subscribe_transient_local: True\r\n  local_costmap_client:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n  local_costmap_rclcpp_node:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n\r\nglobal_costmap:\r\n  global_costmap:\r\n    ros__parameters:\r\n      update_frequency: 1.0\r\n      publish_frequency: 1.0\r\n      global_frame: map\r\n      robot_base_frame: base_link\r\n      use_sim_time: False\r\n      robot_radius: 0.22\r\n      resolution: 0.05\r\n      track_unknown_space: true\r\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\r\n      obstacle_layer:\r\n        plugin: "nav2_costmap_2d::ObstacleLayer"\r\n        enabled: True\r\n        observation_sources: scan\r\n        scan:\r\n          topic: /scan\r\n          max_obstacle_height: 2.0\r\n          clearing: True\r\n          marking: True\r\n          data_type: "LaserScan"\r\n          raytrace_max_range: 3.0\r\n          raytrace_min_range: 0.0\r\n          obstacle_max_range: 2.5\r\n          obstacle_min_range: 0.0\r\n      static_layer:\r\n        plugin: "nav2_costmap_2d::StaticLayer"\r\n        map_subscribe_transient_local: True\r\n      inflation_layer:\r\n        plugin: "nav2_costmap_2d::InflationLayer"\r\n        cost_scaling_factor: 3.0\r\n        inflation_radius: 0.55\r\n  global_costmap_client:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n  global_costmap_rclcpp_node:\r\n    ros__parameters:\r\n      use_sim_time: False\r\n\r\nmap_server:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    yaml_filename: "turtlebot3_world.yaml"\r\n\r\nmap_saver:\r\n  ros__parameters:\r\n    use_sim_time: False\r\n    save_map_timeout: 5.0\r\n    free_thresh_default: 0.25\r\n    occupied_thresh_default: 0.65\r\n    map_subscribe_transient_local: True\r\n\r\nplanner_server:\r\n  ros__parameters:\r\n    expected_planner_frequency: 20.0\r\n    use_sim_time: False\r\n    planner_plugins: ["GridBased"]\r\n    GridBased:\r\n      plugin: "nav2_navfn_planner::NavfnPlanner"\r\n      tolerance: 0.5\r\n      use_astar: false\r\n      allow_unknown: true\r\n\r\nrecoveries_server:\r\n  ros__parameters:\r\n    costmap_topic: local_costmap/costmap_raw\r\n    footprint_topic: local_costmap/published_footprint\r\n    cycle_frequency: 10.0\r\n    recovery_plugins: ["spin", "backup", "wait"]\r\n    spin:\r\n      plugin: "nav2_recoveries::Spin"\r\n    backup:\r\n      plugin: "nav2_recoveries::BackUp"\r\n    wait:\r\n      plugin: "nav2_recoveries::Wait"\r\n    global_frame: odom\r\n    robot_base_frame: base_link\r\n    transform_timeout: 0.1\r\n    use_sim_time: False\r\n    simulate_ahead_time: 2.0\r\n    max_rotational_vel: 1.0\r\n    min_rotational_vel: 0.4\r\n    rotational_acc_lim: 3.2\r\n\r\nrobot_state_publisher:\r\n  ros__parameters:\r\n    use_sim_time: False\n'})}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Create a combined launch file"})," that integrates Isaac ROS VSLAM with Nav2 (",(0,i.jsx)(e.code,{children:"launch/isaac_ros_nav2.launch.py"}),"):"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import os\r\nfrom ament_index_python.packages import get_package_share_directory\r\nfrom launch import LaunchDescription\r\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom launch.substitutions import LaunchConfiguration\r\nfrom launch_ros.actions import ComposableNodeContainer\r\nfrom launch_ros.descriptions import ComposableNode\r\n\r\ndef generate_launch_description():\r\n    # Declare launch arguments\r\n    use_sim_time = DeclareLaunchArgument(\r\n        'use_sim_time',\r\n        default_value='false',\r\n        description='Use simulation (Isaac Sim) clock if true'\r\n    )\r\n    \r\n    # Launch Nav2\r\n    nav2_bringup_launch_dir = os.path.join(\r\n        get_package_share_directory('nav2_bringup'),\r\n        'launch'\r\n    )\r\n    \r\n    nav2_params_path = os.path.join(\r\n        get_package_share_directory('isaac_tutorials'),\r\n        'config',\r\n        'isaac_nav2_params.yaml'\r\n    )\r\n    \r\n    nav2_launch = IncludeLaunchDescription(\r\n        PythonLaunchDescriptionSource(\r\n            os.path.join(nav2_bringup_launch_dir, 'navigation_launch.py')\r\n        ),\r\n        launch_arguments={\r\n            'use_sim_time': LaunchConfiguration('use_sim_time'),\r\n            'params_file': nav2_params_path\r\n        }.items()\r\n    )\r\n    \r\n    # Create Isaac ROS VSLAM container\r\n    vslam_container = ComposableNodeContainer(\r\n        name='vslam_container',\r\n        namespace='',\r\n        package='rclcpp_components',\r\n        executable='component_container_mt',\r\n        composable_node_descriptions=[\r\n            ComposableNode(\r\n                package='isaac_ros_visual_slam',\r\n                plugin='isaac_ros::visual_slam::VisualSlamNode',\r\n                name='visual_slam',\r\n                parameters=[{\r\n                    'use_sim_time': LaunchConfiguration('use_sim_time'),\r\n                    'enable_debug_mode': False,\r\n                    'enable_slam_visualization': True,\r\n                    'enable_landmarks_view': True,\r\n                    'enable_observations_view': True,\r\n                    'map_frame': 'map',\r\n                    'odom_frame': 'odom',\r\n                    'base_frame': 'base_link',\r\n                    'intra_process_comms': True\r\n                }],\r\n                remappings=[\r\n                    ('/visual_slam/integrated_imu', '/imu'),\r\n                    ('/visual_slam/image_raw', '/camera/image_raw'),\r\n                    ('/visual_slam/camera_info', '/camera/camera_info'),\r\n                    ('/visual_slam/visual_odometry', '/visual_odometry'),\r\n                    ('/visual_slam/tracking/landmarks', '/landmarks'),\r\n                ]\r\n            ),\r\n        ],\r\n        output='screen'\r\n    )\r\n    \r\n    # Create launch description\r\n    ld = LaunchDescription()\r\n    ld.add_action(use_sim_time)\r\n    ld.add_action(nav2_launch)\r\n    ld.add_action(vslam_container)\r\n    \r\n    return ld\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"lab-4-performance-comparison-and-optimization",children:"Lab 4: Performance Comparison and Optimization"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Create a performance monitoring node"})," (",(0,i.jsx)(e.code,{children:"isaac_ros_performance_monitor.py"}),"):","\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom nav_msgs.msg import Odometry\r\nfrom geometry_msgs.msg import PoseStamped\r\nfrom std_msgs.msg import Float64MultiArray\r\nimport time\r\nfrom collections import deque\r\nimport statistics\r\n\r\nclass IsaacROSPerformanceMonitor(Node):\r\n    def __init__(self):\r\n        super().__init__('isaac_ros_performance_monitor')\r\n        \r\n        # Subscribers\r\n        self.image_sub = self.create_subscription(\r\n            Image, '/camera/image_raw', self.image_callback, 10)\r\n        self.odom_sub = self.create_subscription(\r\n            Odometry, '/visual_odometry', self.odom_callback, 10)\r\n        self.nav_pose_sub = self.create_subscription(\r\n            PoseStamped, '/goal_pose', self.nav_goal_callback, 10)\r\n        \r\n        # Publisher for performance metrics\r\n        self.metrics_pub = self.create_publisher(\r\n            Float64MultiArray, '/performance_metrics', 10)\r\n        \r\n        # Performance tracking\r\n        self.image_times = deque(maxlen=100)\r\n        self.odom_times = deque(maxlen=100)\r\n        self.last_image_time = None\r\n        self.last_odom_time = None\r\n        \r\n        # Timers\r\n        self.metrics_timer = self.create_timer(2.0, self.publish_metrics)\r\n        \r\n        self.get_logger().info('Isaac ROS Performance Monitor initialized')\r\n    \r\n    def image_callback(self, msg):\r\n        current_time = time.time()\r\n        if self.last_image_time is not None:\r\n            processing_time = current_time  self.last_image_time\r\n            self.image_times.append(processing_time)\r\n        \r\n        self.last_image_time = current_time\r\n    \r\n    def odom_callback(self, msg):\r\n        current_time = time.time()\r\n        if self.last_odom_time is not None:\r\n            update_time = current_time  self.last_odom_time\r\n            self.odom_times.append(update_time)\r\n        \r\n        self.last_odom_time = current_time\r\n    \r\n    def nav_goal_callback(self, msg):\r\n        self.get_logger().info('Navigation goal received')\r\n    \r\n    def publish_metrics(self):\r\n        metrics_msg = Float64MultiArray()\r\n        data = []\r\n        \r\n        # Image processing metrics\r\n        if self.image_times:\r\n            avg_image_proc_time = statistics.mean(self.image_times)\r\n            min_image_proc_time = min(self.image_times)\r\n            max_image_proc_time = max(self.image_times)\r\n            image_freq = len(self.image_times) / 2.0  # over 2 seconds\r\n            \r\n            data.extend([avg_image_proc_time, min_image_proc_time, max_image_proc_time, image_freq])\r\n        \r\n        # Odometry metrics\r\n        if self.odom_times:\r\n            avg_odom_time = statistics.mean(self.odom_times)\r\n            min_odom_time = min(self.odom_times)\r\n            max_odom_time = max(self.odom_times)\r\n            odom_freq = len(self.odom_times) / 2.0  # over 2 seconds\r\n            \r\n            data.extend([avg_odom_time, min_odom_time, max_odom_time, odom_freq])\r\n        \r\n        # GPU utilization (placeholder  would require nvidiamlpy in a real implementation)\r\n        data.append(0.0)  # GPU utilization percentage\r\n        data.append(0.0)  # GPU memory usage\r\n        \r\n        metrics_msg.data = data\r\n        self.metrics_pub.publish(metrics_msg)\r\n        \r\n        # Log metrics\r\n        if len(data) >= 8:  # We have both image and odometry metrics\r\n            self.get_logger().info(\r\n                f'Performance  Image: {data[3]:.1f}Hz (avg: {data[0]*1000:.1f}ms), '\r\n                f'VSLAM: {data[7]:.1f}Hz (avg: {data[4]*1000:.1f}ms)'\r\n            )\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    monitor = IsaacROSPerformanceMonitor()\r\n    \r\n    try:\r\n        rclpy.spin(monitor)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        monitor.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"runnable-code-example",children:"Runnable Code Example"}),"\n",(0,i.jsx)(e.p,{children:"Here's a complete example of a GPUaccelerated visual SLAM system using Isaac ROS:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n# isaac_ros_vslam_system.py\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, CameraInfo, Imu\r\nfrom nav_msgs.msg import Odometry\r\nfrom geometry_msgs.msg import Point, Pose, Quaternion\r\nfrom tf2_ros import TransformBroadcaster\r\nfrom tf_transformations import quaternion_from_euler, euler_from_quaternion\r\nfrom std_msgs.msg import Header\r\nimport numpy as np\r\nimport cv2\r\nfrom cv_bridge import CvBridge\r\nimport message_filters\r\nfrom scipy.spatial.transform import Rotation as R\r\n\r\nclass IsaacROSVisualSLAMSystem(Node):\r\n    def __init__(self):\r\n        super().__init__('isaac_ros_vslam_system')\r\n        \r\n        # Initialize CvBridge\r\n        self.bridge = CvBridge()\r\n        \r\n        # TF broadcaster\r\n        self.tf_broadcaster = TransformBroadcaster(self)\r\n        \r\n        # State variables\r\n        self.prev_image = None\r\n        self.current_pose = np.eye(4)  # 4x4 transformation matrix\r\n        self.pose_covariance = np.eye(6) * 0.1  # Simple covariance matrix\r\n        self.frame_count = 0\r\n        \r\n        # Camera parameters (these should match your camera calibration)\r\n        self.camera_matrix = np.array([\r\n            [320.0, 0.0, 320.0],\r\n            [0.0, 320.0, 240.0],\r\n            [0.0, 0.0, 1.0]\r\n        ])\r\n        \r\n        # Initialize feature detector and matcher for comparison\r\n        # In a real Isaac ROS implementation, these would be GPUaccelerated\r\n        self.feature_detector = cv2.ORB_create(nfeatures=1000)\r\n        self.feature_matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\r\n        \r\n        # Subscribers\r\n        image_sub = message_filters.Subscriber(self, Image, '/camera/image_raw')\r\n        camera_info_sub = message_filters.Subscriber(self, CameraInfo, '/camera/camera_info')\r\n        imu_sub = message_filters.Subscriber(self, Imu, '/imu')\r\n        \r\n        # Synchronize topics\r\n        self.sync = message_filters.ApproximateTimeSynchronizer(\r\n            [image_sub, camera_info_sub, imu_sub], \r\n            queue_size=10, \r\n            slop=0.1\r\n        )\r\n        self.sync.registerCallback(self.synced_callback)\r\n        \r\n        # Publishers\r\n        self.odom_pub = self.create_publisher(Odometry, '/visual_odometry', 10)\r\n        self.pose_pub = self.create_publisher(Pose, '/estimated_pose', 10)\r\n        \r\n        self.get_logger().info('Isaac ROS Visual SLAM System initialized')\r\n    \r\n    def synced_callback(self, image_msg, camera_info_msg, imu_msg):\r\n        \"\"\"Process synchronized image, camera info, and IMU data\"\"\"\r\n        try:\r\n            # Convert ROS Image message to OpenCV image\r\n            cv_image = self.bridge.imgmsg_to_cv2(image_msg, \"bgr8\")\r\n            \r\n            # Update camera matrix if camera info changed\r\n            self.camera_matrix = np.array(camera_info_msg.k).reshape(3, 3)\r\n            \r\n            # Process visual features using Isaac ROS equivalent processing\r\n            pose_change = self.process_visual_features(cv_image)\r\n            \r\n            if pose_change is not None:\r\n                # Update global pose\r\n                self.current_pose = self.current_pose @ pose_change\r\n                \r\n                # Publish odometry and pose\r\n                self.publish_odometry(image_msg.header.stamp, imu_msg)\r\n                self.publish_pose(image_msg.header.stamp)\r\n                \r\n                # Broadcast TF transform\r\n                self.broadcast_transform(image_msg.header.stamp)\r\n                \r\n                self.frame_count += 1\r\n                if self.frame_count % 30 == 0:  # Log every 30 frames\r\n                    self.get_logger().info(f'Processed frame {self.frame_count}, pose: {self.current_pose[:3, 3]}')\r\n            \r\n            # Store current image for next iteration\r\n            self.prev_image = cv_image\r\n            \r\n        except Exception as e:\r\n            self.get_logger().error(f'Error in synced callback: {str(e)}')\r\n    \r\n    def process_visual_features(self, current_image):\r\n        \"\"\"Process visual features to estimate pose change (simplified version)\"\"\"\r\n        if self.prev_image is None:\r\n            return None\r\n        \r\n        try:\r\n            # Convert images to grayscale\r\n            prev_gray = cv2.cvtColor(self.prev_image, cv2.COLOR_BGR2GRAY)\r\n            curr_gray = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)\r\n            \r\n            # Detect features using Isaac ROS equivalent\r\n            # In real Isaac ROS: This would be GPUaccelerated\r\n            prev_kp, prev_desc = self.feature_detector.detectAndCompute(prev_gray, None)\r\n            curr_kp, curr_desc = self.feature_detector.detectAndCompute(curr_gray, None)\r\n            \r\n            if prev_desc is None or curr_desc is None or len(prev_desc) < 10 or len(curr_desc) < 10:\r\n                return None\r\n            \r\n            # Match features\r\n            matches = self.feature_matcher.knnMatch(prev_desc, curr_desc, k=2)\r\n            \r\n            # Apply Lowe's ratio test for filtering\r\n            good_matches = []\r\n            for match_pair in matches:\r\n                if len(match_pair) == 2:\r\n                    m, n = match_pair\r\n                    if m.distance < 0.75 * n.distance:\r\n                        good_matches.append(m)\r\n            \r\n            if len(good_matches) < 10:\r\n                return None\r\n            \r\n            # Extract matched points\r\n            prev_pts = np.float32([prev_kp[m.queryIdx].pt for m in good_matches]).reshape(1, 1, 2)\r\n            curr_pts = np.float32([curr_kp[m.trainIdx].pt for m in good_matches]).reshape(1, 1, 2)\r\n            \r\n            # Estimate essential matrix and decompose to get rotation and translation\r\n            E, mask = cv2.findEssentialMat(\r\n                curr_pts, prev_pts, self.camera_matrix, \r\n                method=cv2.RANSAC, prob=0.999, threshold=1.0\r\n            )\r\n            \r\n            if E is None or len(E) < 3:\r\n                return None\r\n            \r\n            # Take only the first 3x3 of E if multiple solutions returned\r\n            if E.shape[0] > 3:\r\n                E = E[:3, :3]\r\n            \r\n            # Decompose essential matrix\r\n            _, R, t, _ = cv2.recoverPose(E, curr_pts, prev_pts, self.camera_matrix)\r\n            \r\n            # Check if translation is reasonable (avoid outliers)\r\n            translation_norm = np.linalg.norm(t)\r\n            if translation_norm > 5.0:  # Limit to 5m per frame\r\n                return None\r\n            \r\n            # Create transformation matrix\r\n            pose_change = np.eye(4)\r\n            pose_change[:3, :3] = R\r\n            pose_change[:3, 3] = t.flatten()\r\n            \r\n            # Apply scaling based on IMU integration if available\r\n            # In Isaac ROS, this would be handled by the fusion algorithm\r\n            return pose_change\r\n            \r\n        except Exception as e:\r\n            self.get_logger().error(f'Error processing visual features: {str(e)}')\r\n            return None\r\n    \r\n    def publish_odometry(self, timestamp, imu_msg):\r\n        \"\"\"Publish odometry message\"\"\"\r\n        odom_msg = Odometry()\r\n        odom_msg.header.stamp = timestamp\r\n        odom_msg.header.frame_id = 'odom'\r\n        odom_msg.child_frame_id = 'base_link'\r\n        \r\n        # Extract position and orientation from transformation matrix\r\n        position = self.current_pose[:3, 3]\r\n        rotation_matrix = self.current_pose[:3, :3]\r\n        rotation = R.from_matrix(rotation_matrix)\r\n        quat = rotation.as_quat()  # x, y, z, w format\r\n        \r\n        # Set position\r\n        odom_msg.pose.pose.position = Point(x=position[0], y=position[1], z=position[2])\r\n        odom_msg.pose.pose.orientation = Quaternion(x=quat[0], y=quat[1], z=quat[2], w=quat[3])\r\n        \r\n        # Set covariance\r\n        odom_msg.pose.covariance = self.pose_covariance.flatten().tolist()\r\n        \r\n        # Set velocity from IMU if available\r\n        odom_msg.twist.twist.linear.x = imu_msg.linear_acceleration.x\r\n        odom_msg.twist.twist.linear.y = imu_msg.linear_acceleration.y\r\n        odom_msg.twist.twist.angular.z = imu_msg.angular_velocity.z\r\n        \r\n        self.odom_pub.publish(odom_msg)\r\n    \r\n    def publish_pose(self, timestamp):\r\n        \"\"\"Publish pose message\"\"\"\r\n        pose_msg = Pose()\r\n        \r\n        position = self.current_pose[:3, 3]\r\n        rotation_matrix = self.current_pose[:3, :3]\r\n        rotation = R.from_matrix(rotation_matrix)\r\n        quat = rotation.as_quat()\r\n        \r\n        pose_msg.position = Point(x=position[0], y=position[1], z=position[2])\r\n        pose_msg.orientation = Quaternion(x=quat[0], y=quat[1], z=quat[2], w=quat[3])\r\n        \r\n        self.pose_pub.publish(pose_msg)\r\n    \r\n    def broadcast_transform(self, timestamp):\r\n        \"\"\"Broadcast TF transform\"\"\"\r\n        from geometry_msgs.msg import TransformStamped\r\n        \r\n        t = TransformStamped()\r\n        \r\n        # Header\r\n        t.header.stamp = timestamp\r\n        t.header.frame_id = 'odom'\r\n        t.child_frame_id = 'base_link'\r\n        \r\n        # Set transform\r\n        position = self.current_pose[:3, 3]\r\n        rotation_matrix = self.current_pose[:3, :3]\r\n        rotation = R.from_matrix(rotation_matrix)\r\n        quat = rotation.as_quat()\r\n        \r\n        t.transform.translation.x = position[0]\r\n        t.transform.translation.y = position[1]\r\n        t.transform.translation.z = position[2]\r\n        \r\n        t.transform.rotation.x = quat[0]\r\n        t.transform.rotation.y = quat[1]\r\n        t.transform.rotation.z = quat[2]\r\n        t.transform.rotation.w = quat[3]\r\n        \r\n        self.tf_broadcaster.sendTransform(t)\r\n\r\nclass IsaacROSNavPipeline(Node):\r\n    def __init__(self):\r\n        super().__init__('isaac_ros_nav_pipeline')\r\n        \r\n        # Subscribe to visual odometry from SLAM system\r\n        self.slam_odom_sub = self.create_subscription(\r\n            Odometry, '/visual_odometry', self.odom_callback, 10)\r\n        \r\n        # Publisher for navigation commands\r\n        self.cmd_vel_pub = self.create_publisher(\r\n            Odometry, '/cmd_vel', 10)\r\n        \r\n        self.get_logger().info('Isaac ROS Navigation Pipeline initialized')\r\n    \r\n    def odom_callback(self, msg):\r\n        \"\"\"Process odometry from SLAM system\"\"\"\r\n        # In a real system, this would interface with Nav2\r\n        # For this example, we'll just log the position\r\n        position = msg.pose.pose.position\r\n        orientation = msg.pose.pose.orientation\r\n        \r\n        self.get_logger().info(\r\n            f'SLAM Position: ({position.x:.2f}, {position.y:.2f}, {position.z:.2f}), '\r\n            f'Orientation: ({orientation.x:.2f}, {orientation.y:.2f}, {orientation.z:.2f}, {orientation.w:.2f})'\r\n        )\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    \r\n    # Create nodes\r\n    slam_node = IsaacROSVisualSLAMSystem()\r\n    nav_node = IsaacROSNavPipeline()\r\n    \r\n    try:\r\n        # Create executor and add nodes\r\n        executor = rclpy.executors.MultiThreadedExecutor()\r\n        executor.add_node(slam_node)\r\n        executor.add_node(nav_node)\r\n        \r\n        # Spin both nodes\r\n        executor.spin()\r\n        \r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        slam_node.destroy_node()\r\n        nav_node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsx)(e.h3,{id:"isaac-ros-launch-file-for-complete-system",children:"Isaac ROS Launch File for Complete System"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:"<! launch/complete_isaac_ros_system.launch.py >\r\nimport os\r\nfrom ament_index_python.packages import get_package_share_directory\r\nfrom launch import LaunchDescription\r\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, GroupAction\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom launch.substitutions import LaunchConfiguration\r\nfrom launch_ros.actions import ComposableNodeContainer, Node, SetParameter\r\nfrom launch_ros.descriptions import ComposableNode\r\n\r\ndef generate_launch_description():\r\n    # Declare launch arguments\r\n    use_sim_time = DeclareLaunchArgument(\r\n        'use_sim_time',\r\n        default_value='false',\r\n        description='Use simulation (Isaac Sim) clock if true'\r\n    )\r\n    \r\n    # Create parameter overrides\r\n    params_file = LaunchConfiguration('params_file')\r\n    params_launch_arg = DeclareLaunchArgument(\r\n        'params_file',\r\n        default_value=os.path.join(\r\n            get_package_share_directory('isaac_tutorials'),\r\n            'config',\r\n            'isaac_ros_params.yaml'\r\n        ),\r\n        description='Full path to params file for all nodes'\r\n    )\r\n    \r\n    # Isaac ROS VSLAM container\r\n    vslam_container = ComposableNodeContainer(\r\n        name='vslam_container',\r\n        namespace='',\r\n        package='rclcpp_components',\r\n        executable='component_container_mt',\r\n        composable_node_descriptions=[\r\n            ComposableNode(\r\n                package='isaac_ros_visual_slam',\r\n                plugin='isaac_ros::visual_slam::VisualSlamNode',\r\n                name='visual_slam',\r\n                parameters=[{\r\n                    'use_sim_time': LaunchConfiguration('use_sim_time'),\r\n                    'enable_debug_mode': False,\r\n                    'enable_slam_visualization': True,\r\n                    'enable_landmarks_view': True,\r\n                    'enable_observations_view': True,\r\n                    'map_frame': 'map',\r\n                    'odom_frame': 'odom',\r\n                    'base_frame': 'base_link',\r\n                    'intra_process_comms': True\r\n                }],\r\n                remappings=[\r\n                    ('/visual_slam/integrated_imu', '/imu'),\r\n                    ('/visual_slam/image_raw', '/camera/image_raw'),\r\n                    ('/visual_slam/camera_info', '/camera/camera_info'),\r\n                    ('/visual_slam/visual_odometry', '/visual_odometry'),\r\n                    ('/visual_slam/tracking/landmarks', '/landmarks'),\r\n                ]\r\n            ),\r\n        ],\r\n        output='screen'\r\n    )\r\n    \r\n    # Isaac ROS Image Pipeline container\r\n    image_container = ComposableNodeContainer(\r\n        name='image_container',\r\n        namespace='',\r\n        package='rclcpp_components',\r\n        executable='component_container_mt',\r\n        composable_node_descriptions=[\r\n            ComposableNode(\r\n                package='isaac_ros_image_rectifier',\r\n                plugin='nvidia::isaac_ros::image_rectifier::RectifyNode',\r\n                name='image_rectifier_node',\r\n                parameters=[{\r\n                    'use_sim_time': LaunchConfiguration('use_sim_time'),\r\n                    'input_width': 640,\r\n                    'input_height': 480,\r\n                    'output_width': 640,\r\n                    'output_height': 480,\r\n                }],\r\n                remappings=[\r\n                    ('image_raw', '/camera/image_raw'),\r\n                    ('camera_info', '/camera/camera_info'),\r\n                    ('image_rect', '/rectified/image_raw'),\r\n                    ('camera_info_rect', '/rectified/camera_info')\r\n                ]\r\n            )\r\n        ],\r\n        output='screen'\r\n    )\r\n    \r\n    # Performance monitor node\r\n    perf_monitor = Node(\r\n        package='isaac_tutorials',\r\n        executable='isaac_ros_performance_monitor',\r\n        name='isaac_ros_performance_monitor',\r\n        parameters=[{'use_sim_time': LaunchConfiguration('use_sim_time')}],\r\n        output='screen'\r\n    )\r\n    \r\n    # Create launch description\r\n    ld = LaunchDescription()\r\n    ld.add_action(use_sim_time)\r\n    ld.add_action(params_launch_arg)\r\n    ld.add_action(vslam_container)\r\n    ld.add_action(image_container)\r\n    ld.add_action(perf_monitor)\r\n    \r\n    return ld\n"})}),"\n",(0,i.jsx)(e.h2,{id:"miniproject",children:"Miniproject"}),"\n",(0,i.jsx)(e.p,{children:"Create a complete Isaac ROS navigation system that:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Implements GPUaccelerated Visual SLAM using Isaac ROS components"}),"\n",(0,i.jsx)(e.li,{children:"Integrates with the Nav2 navigation stack"}),"\n",(0,i.jsx)(e.li,{children:"Processes real or simulated camera and IMU data"}),"\n",(0,i.jsx)(e.li,{children:"Creates maps and localizes the robot in realtime"}),"\n",(0,i.jsx)(e.li,{children:"Implements obstacle avoidance using Isaac ROS perception"}),"\n",(0,i.jsx)(e.li,{children:"Benchmarks performance against standard ROS 2 implementations"}),"\n",(0,i.jsx)(e.li,{children:"Documents the performance improvements achieved with GPU acceleration"}),"\n",(0,i.jsx)(e.li,{children:"Creates a visualization showing the SLAM map and navigation path"}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Your project should include:\r\nComplete Isaac ROS VSLAM pipeline\r\nIntegration with Nav2 for navigation\r\nPerformance monitoring tools\r\nVisualization of SLAM and navigation\r\nBenchmarking results showing GPU acceleration benefits\r\nDocumentation of the complete system"}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"This chapter covered Isaac ROS hardwareaccelerated Visual SLAM and Navigation:"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Isaac ROS Architecture"}),": Understanding the GPUaccelerated perception pipeline\r\n",(0,i.jsx)(e.strong,{children:"Visual SLAM Implementation"}),": Setting up and configuring Isaac ROS VSLAM\r\n",(0,i.jsx)(e.strong,{children:"Nav2 Integration"}),": Connecting Isaac ROS components with the navigation stack\r\n",(0,i.jsx)(e.strong,{children:"Performance Optimization"}),": Techniques to maximize GPU utilization\r\n",(0,i.jsx)(e.strong,{children:"System Integration"}),": Creating complete perception and navigation systems\r\n",(0,i.jsx)(e.strong,{children:"Benchmarking"}),": Methods to quantify performance improvements"]}),"\n",(0,i.jsx)(e.p,{children:"Isaac ROS provides significant performance improvements for robotics perception and navigation tasks through GPU acceleration, enabling realtime processing of complex sensor data and more responsive robot behavior."})]})}function d(r={}){const{wrapper:e}={...(0,s.R)(),...r.components};return e?(0,i.jsx)(e,{...r,children:(0,i.jsx)(m,{...r})}):m(r)}}}]);